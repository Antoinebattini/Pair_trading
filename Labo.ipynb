{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pair trading strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and cleanning of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run packages.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (0.2.51)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from yfinance) (2.0.2)\n",
      "Requirement already satisfied: requests>=2.31 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from yfinance) (5.3.0)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: pytz>=2022.5 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from yfinance) (2024.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from yfinance) (3.17.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
      "Requirement already satisfied: six>=1.9 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from pandas>=1.3.0->yfinance) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from requests>=2.31->yfinance) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from requests>=2.31->yfinance) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mcbookairdebat/.venv/lib/python3.9/site-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "tables = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_list = pd.DataFrame(tables[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_list.drop(['Security','GICS Sub-Industry','Headquarters Location','CIK','Founded'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock_list['Date added'] = pd.to_datetime(Stock_list['Date added'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AOS', 'AMD', 'ALB', 'ARE', 'ALGN', 'LNT', 'AMCR', 'AWK', 'ANSS', 'ANET', 'AJG', 'ATO', 'BKR', 'BR', 'CDNS', 'CBOE', 'CDW', 'CE', 'CNC', 'CHTR', 'CHD', 'CFG', 'COO', 'CPRT', 'CPAY', 'CTVA', 'FANG', 'DLR', 'D', 'DOW', 'DD', 'EQIX', 'EG', 'EVRG', 'EXR', 'FRT', 'FTNT', 'FTV', 'FOXA', 'FOX', 'IT', 'GPN', 'HCA', 'HSIC', 'HPE', 'HLT', 'HOLX', 'HWM', 'HII', 'IEX', 'IDXX', 'INCY', 'IQV', 'JBHT', 'JKHY', 'KEYS', 'KHC', 'LW', 'LVS', 'LDOS', 'LYV', 'LKQ', 'MKTX', 'MTD', 'MGM', 'MAA', 'MSCI', 'NWS', 'NCLH', 'NVR', 'ODFL', 'PKG', 'PYPL', 'RJF', 'O', 'REG', 'RMD', 'ROL', 'SBAC', 'SRE', 'NOW', 'SWKS', 'STE', 'SYF', 'SNPS', 'TMUS', 'TROW', 'TTWO', 'TFX', 'TDG', 'UDR', 'ULTA', 'UAL', 'VRSK', 'WRB', 'WAB', 'WTW', 'ZBRA']\n"
     ]
    }
   ],
   "source": [
    "stock_lists = Stock_list[( Stock_list['Date added'] < '2019-12-31') & (Stock_list['Date added']>'2015-01-01')][['Symbol','GICS Sector']]\n",
    "print(list(stock_lists['Symbol']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_list = [yf.download(stock,start='2018-01-01',end='2019-12-31',period='1d')['Close'] for stock in stock_lists['Symbol']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Ticker            AOS\n",
       " Date                 \n",
       " 2018-01-02  54.426804\n",
       " 2018-01-03  54.754097\n",
       " 2018-01-04  55.010609\n",
       " 2018-01-05  55.718262\n",
       " 2018-01-08  55.983627\n",
       " ...               ...\n",
       " 2019-12-23  43.067318\n",
       " 2019-12-24  43.396214\n",
       " 2019-12-26  43.615486\n",
       " 2019-12-27  43.679447\n",
       " 2019-12-30  43.460167\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            AMD\n",
       " Date                 \n",
       " 2018-01-02  10.980000\n",
       " 2018-01-03  11.550000\n",
       " 2018-01-04  12.120000\n",
       " 2018-01-05  11.880000\n",
       " 2018-01-08  12.280000\n",
       " ...               ...\n",
       " 2019-12-23  45.459999\n",
       " 2019-12-24  46.540001\n",
       " 2019-12-26  46.630001\n",
       " 2019-12-27  46.180000\n",
       " 2019-12-30  45.520000\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             ALB\n",
       " Date                  \n",
       " 2018-01-02  120.240570\n",
       " 2018-01-03  120.478241\n",
       " 2018-01-04  119.042999\n",
       " 2018-01-05  120.414230\n",
       " 2018-01-08  125.652405\n",
       " ...                ...\n",
       " 2019-12-23   68.524300\n",
       " 2019-12-24   68.420219\n",
       " 2019-12-26   68.581047\n",
       " 2019-12-27   68.126961\n",
       " 2019-12-30   68.051270\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             ARE\n",
       " Date                  \n",
       " 2018-01-02  103.413986\n",
       " 2018-01-03  102.928497\n",
       " 2018-01-04  100.875023\n",
       " 2018-01-05  101.081947\n",
       " 2018-01-08  101.304810\n",
       " ...                ...\n",
       " 2019-12-23  133.417725\n",
       " 2019-12-24  134.163544\n",
       " 2019-12-26  134.104874\n",
       " 2019-12-27  134.414917\n",
       " 2019-12-30  134.667969\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            ALGN\n",
       " Date                  \n",
       " 2018-01-02  224.619995\n",
       " 2018-01-03  231.199997\n",
       " 2018-01-04  233.300003\n",
       " 2018-01-05  241.070007\n",
       " 2018-01-08  248.899994\n",
       " ...                ...\n",
       " 2019-12-23  278.140015\n",
       " 2019-12-24  277.890015\n",
       " 2019-12-26  278.260010\n",
       " 2019-12-27  277.640015\n",
       " 2019-12-30  275.630005\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            LNT\n",
       " Date                 \n",
       " 2018-01-02  33.802242\n",
       " 2018-01-03  33.505241\n",
       " 2018-01-04  33.111908\n",
       " 2018-01-05  32.975445\n",
       " 2018-01-08  33.344696\n",
       " ...               ...\n",
       " 2019-12-23  46.359463\n",
       " 2019-12-24  46.333855\n",
       " 2019-12-26  46.291168\n",
       " 2019-12-27  46.393616\n",
       " 2019-12-30  46.427761\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker          AMCR\n",
       " Date                \n",
       " 2018-01-02  8.578913\n",
       " 2018-01-03  8.578913\n",
       " 2018-01-04  8.578913\n",
       " 2018-01-05  8.578913\n",
       " 2018-01-08  8.578913\n",
       " ...              ...\n",
       " 2019-12-23  8.732618\n",
       " 2019-12-24  8.636567\n",
       " 2019-12-26  8.684593\n",
       " 2019-12-27  8.764634\n",
       " 2019-12-30  8.684593\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             AWK\n",
       " Date                  \n",
       " 2018-01-02   78.360664\n",
       " 2018-01-03   77.806465\n",
       " 2018-01-04   77.067551\n",
       " 2018-01-05   76.311050\n",
       " 2018-01-08   76.970795\n",
       " ...                ...\n",
       " 2019-12-23  111.023430\n",
       " 2019-12-24  111.233780\n",
       " 2019-12-26  111.471573\n",
       " 2019-12-27  112.459343\n",
       " 2019-12-30  112.541672\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            ANSS\n",
       " Date                  \n",
       " 2018-01-02  148.550003\n",
       " 2018-01-03  151.419998\n",
       " 2018-01-04  151.820007\n",
       " 2018-01-05  152.449997\n",
       " 2018-01-08  153.710007\n",
       " ...                ...\n",
       " 2019-12-23  255.729996\n",
       " 2019-12-24  256.489990\n",
       " 2019-12-26  258.329987\n",
       " 2019-12-27  258.679993\n",
       " 2019-12-30  256.799988\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker           ANET\n",
       " Date                 \n",
       " 2018-01-02  14.439375\n",
       " 2018-01-03  14.725000\n",
       " 2018-01-04  14.543125\n",
       " 2018-01-05  14.798125\n",
       " 2018-01-08  15.691250\n",
       " ...               ...\n",
       " 2019-12-23  12.804375\n",
       " 2019-12-24  12.790000\n",
       " 2019-12-26  12.850625\n",
       " 2019-12-27  12.776875\n",
       " 2019-12-30  12.695625\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            AJG\n",
       " Date                 \n",
       " 2018-01-02  56.019924\n",
       " 2018-01-03  56.443420\n",
       " 2018-01-04  56.966053\n",
       " 2018-01-05  57.227371\n",
       " 2018-01-08  57.263412\n",
       " ...               ...\n",
       " 2019-12-23  88.649040\n",
       " 2019-12-24  88.931168\n",
       " 2019-12-26  88.921776\n",
       " 2019-12-27  89.109879\n",
       " 2019-12-30  89.250931\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            ATO\n",
       " Date                 \n",
       " 2018-01-02  71.803062\n",
       " 2018-01-03  71.212029\n",
       " 2018-01-04  70.908066\n",
       " 2018-01-05  70.241028\n",
       " 2018-01-08  70.460579\n",
       " ...               ...\n",
       " 2019-12-23  97.922379\n",
       " 2019-12-24  97.455299\n",
       " 2019-12-26  97.384781\n",
       " 2019-12-27  97.058708\n",
       " 2019-12-30  97.358353\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            BKR\n",
       " Date                 \n",
       " 2018-01-02  26.287893\n",
       " 2018-01-03  27.348221\n",
       " 2018-01-04  28.245426\n",
       " 2018-01-05  28.090446\n",
       " 2018-01-08  28.147547\n",
       " ...               ...\n",
       " 2019-12-23  21.983507\n",
       " 2019-12-24  21.957657\n",
       " 2019-12-26  22.026596\n",
       " 2019-12-27  21.966272\n",
       " 2019-12-30  22.086918\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker              BR\n",
       " Date                  \n",
       " 2018-01-02   80.694069\n",
       " 2018-01-03   80.622963\n",
       " 2018-01-04   81.262856\n",
       " 2018-01-05   82.258163\n",
       " 2018-01-08   82.764748\n",
       " ...                ...\n",
       " 2019-12-23  112.757706\n",
       " 2019-12-24  112.941269\n",
       " 2019-12-26  112.537445\n",
       " 2019-12-27  113.078926\n",
       " 2019-12-30  112.693466\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker           CDNS\n",
       " Date                 \n",
       " 2018-01-02  42.049999\n",
       " 2018-01-03  42.930000\n",
       " 2018-01-04  43.580002\n",
       " 2018-01-05  43.990002\n",
       " 2018-01-08  44.919998\n",
       " ...               ...\n",
       " 2019-12-23  70.139999\n",
       " 2019-12-24  69.650002\n",
       " 2019-12-26  70.050003\n",
       " 2019-12-27  70.290001\n",
       " 2019-12-30  69.989998\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            CBOE\n",
       " Date                  \n",
       " 2018-01-02  111.431602\n",
       " 2018-01-03  112.166931\n",
       " 2018-01-04  112.602654\n",
       " 2018-01-05  115.834412\n",
       " 2018-01-08  117.586418\n",
       " ...                ...\n",
       " 2019-12-23  111.159729\n",
       " 2019-12-24  111.789284\n",
       " 2019-12-26  111.864464\n",
       " 2019-12-27  111.667130\n",
       " 2019-12-30  112.052383\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             CDW\n",
       " Date                  \n",
       " 2018-01-02   64.377403\n",
       " 2018-01-03   66.260017\n",
       " 2018-01-04   67.422783\n",
       " 2018-01-05   67.312042\n",
       " 2018-01-08   67.413574\n",
       " ...                ...\n",
       " 2019-12-23  134.861954\n",
       " 2019-12-24  134.956375\n",
       " 2019-12-26  136.523346\n",
       " 2019-12-27  135.890869\n",
       " 2019-12-30  134.777008\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker              CE\n",
       " Date                  \n",
       " 2018-01-02   91.720657\n",
       " 2018-01-03   92.081520\n",
       " 2018-01-04   92.133049\n",
       " 2018-01-05   93.000778\n",
       " 2018-01-08   93.413177\n",
       " ...                ...\n",
       " 2019-12-23  110.332451\n",
       " 2019-12-24  110.493645\n",
       " 2019-12-26  110.242912\n",
       " 2019-12-27  110.430962\n",
       " 2019-12-30  109.875786\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            CNC\n",
       " Date                 \n",
       " 2018-01-02  51.294998\n",
       " 2018-01-03  52.215000\n",
       " 2018-01-04  51.250000\n",
       " 2018-01-05  52.744999\n",
       " 2018-01-08  52.459999\n",
       " ...               ...\n",
       " 2019-12-23  62.900002\n",
       " 2019-12-24  63.230000\n",
       " 2019-12-26  63.400002\n",
       " 2019-12-27  63.650002\n",
       " 2019-12-30  63.040001\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            CHTR\n",
       " Date                  \n",
       " 2018-01-02  348.970001\n",
       " 2018-01-03  353.029999\n",
       " 2018-01-04  349.790009\n",
       " 2018-01-05  350.880005\n",
       " 2018-01-08  356.549988\n",
       " ...                ...\n",
       " 2019-12-23  480.720001\n",
       " 2019-12-24  480.859985\n",
       " 2019-12-26  485.730011\n",
       " 2019-12-27  483.690002\n",
       " 2019-12-30  483.079987\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            CHD\n",
       " Date                 \n",
       " 2018-01-02  45.282753\n",
       " 2018-01-03  44.989594\n",
       " 2018-01-04  45.749950\n",
       " 2018-01-05  45.869041\n",
       " 2018-01-08  46.207996\n",
       " ...               ...\n",
       " 2019-12-23  66.168549\n",
       " 2019-12-24  66.357178\n",
       " 2019-12-26  66.376053\n",
       " 2019-12-27  66.687294\n",
       " 2019-12-30  66.357178\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            CFG\n",
       " Date                 \n",
       " 2018-01-02  31.790277\n",
       " 2018-01-03  32.155251\n",
       " 2018-01-04  32.535118\n",
       " 2018-01-05  32.684086\n",
       " 2018-01-08  32.818169\n",
       " ...               ...\n",
       " 2019-12-23  32.048290\n",
       " 2019-12-24  32.103764\n",
       " 2019-12-26  32.293961\n",
       " 2019-12-27  32.079987\n",
       " 2019-12-30  32.040371\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            COO\n",
       " Date                 \n",
       " 2018-01-02  55.093136\n",
       " 2018-01-03  56.621422\n",
       " 2018-01-04  55.824818\n",
       " 2018-01-05  57.560371\n",
       " 2018-01-08  57.847549\n",
       " ...               ...\n",
       " 2019-12-23  80.113487\n",
       " 2019-12-24  80.458244\n",
       " 2019-12-26  79.948593\n",
       " 2019-12-27  80.223419\n",
       " 2019-12-30  79.808693\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker           CPRT\n",
       " Date                 \n",
       " 2018-01-02  10.900000\n",
       " 2018-01-03  10.847500\n",
       " 2018-01-04  10.935000\n",
       " 2018-01-05  10.882500\n",
       " 2018-01-08  10.887500\n",
       " ...               ...\n",
       " 2019-12-23  22.467501\n",
       " 2019-12-24  22.727501\n",
       " 2019-12-26  22.754999\n",
       " 2019-12-27  22.705000\n",
       " 2019-12-30  22.715000\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            CPAY\n",
       " Date                  \n",
       " 2018-01-02  193.869995\n",
       " 2018-01-03  194.960007\n",
       " 2018-01-04  195.460007\n",
       " 2018-01-05  197.000000\n",
       " 2018-01-08  197.160004\n",
       " ...                ...\n",
       " 2019-12-23  284.559998\n",
       " 2019-12-24  285.470001\n",
       " 2019-12-26  283.000000\n",
       " 2019-12-27  285.820007\n",
       " 2019-12-30  286.260010\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker           CTVA\n",
       " Date                 \n",
       " 2019-05-24  26.942566\n",
       " 2019-05-28  26.724247\n",
       " 2019-05-29  26.478043\n",
       " 2019-05-30  26.756760\n",
       " 2019-05-31  25.056591\n",
       " ...               ...\n",
       " 2019-12-23  26.882545\n",
       " 2019-12-24  27.023247\n",
       " 2019-12-26  27.379679\n",
       " 2019-12-27  27.332779\n",
       " 2019-12-30  27.070148\n",
       " \n",
       " [152 rows x 1 columns],\n",
       " Ticker            FANG\n",
       " Date                  \n",
       " 2018-01-02  101.695526\n",
       " 2018-01-03  102.721405\n",
       " 2018-01-04  103.484848\n",
       " 2018-01-05  103.365547\n",
       " 2018-01-08  104.168755\n",
       " ...                ...\n",
       " 2019-12-23   71.545609\n",
       " 2019-12-24   72.469788\n",
       " 2019-12-26   73.377853\n",
       " 2019-12-27   72.943893\n",
       " 2019-12-30   73.184998\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            DLR\n",
       " Date                 \n",
       " 2018-01-02  87.942291\n",
       " 2018-01-03  88.746315\n",
       " 2018-01-04  87.645645\n",
       " 2018-01-05  88.207703\n",
       " 2018-01-08  89.105377\n",
       " ...               ...\n",
       " 2019-12-23  97.866631\n",
       " 2019-12-24  97.967339\n",
       " 2019-12-26  99.117027\n",
       " 2019-12-27  99.175781\n",
       " 2019-12-30  99.284874\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker              D\n",
       " Date                 \n",
       " 2018-01-02  58.932442\n",
       " 2018-01-03  56.664124\n",
       " 2018-01-04  56.399864\n",
       " 2018-01-05  56.407192\n",
       " 2018-01-08  57.273411\n",
       " ...               ...\n",
       " 2019-12-23  65.689194\n",
       " 2019-12-24  65.632729\n",
       " 2019-12-26  65.713394\n",
       " 2019-12-27  66.149010\n",
       " 2019-12-30  66.213531\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            DOW\n",
       " Date                 \n",
       " 2019-03-20  36.684486\n",
       " 2019-03-21  36.080437\n",
       " 2019-03-22  35.800522\n",
       " 2019-03-25  36.205669\n",
       " 2019-03-26  35.984680\n",
       " ...               ...\n",
       " 2019-12-23  42.275009\n",
       " 2019-12-24  42.251930\n",
       " 2019-12-26  42.498203\n",
       " 2019-12-27  42.198055\n",
       " 2019-12-30  41.820938\n",
       " \n",
       " [198 rows x 1 columns],\n",
       " Ticker             DD\n",
       " Date                 \n",
       " 2018-01-02  88.996758\n",
       " 2018-01-03  90.420204\n",
       " 2018-01-04  92.153099\n",
       " 2018-01-05  93.353752\n",
       " 2018-01-08  93.031929\n",
       " ...               ...\n",
       " 2019-12-23  57.998543\n",
       " 2019-12-24  57.871494\n",
       " 2019-12-26  57.826138\n",
       " 2019-12-27  57.826138\n",
       " 2019-12-30  56.519539\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            EQIX\n",
       " Date                  \n",
       " 2018-01-02  391.925781\n",
       " 2018-01-03  393.732269\n",
       " 2018-01-04  392.828979\n",
       " 2018-01-05  394.179535\n",
       " 2018-01-08  401.817719\n",
       " ...                ...\n",
       " 2019-12-23  523.098328\n",
       " 2019-12-24  524.562256\n",
       " 2019-12-26  530.299988\n",
       " 2019-12-27  533.035889\n",
       " 2019-12-30  530.967896\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker              EG\n",
       " Date                  \n",
       " 2018-01-02  187.764603\n",
       " 2018-01-03  190.626984\n",
       " 2018-01-04  192.361755\n",
       " 2018-01-05  192.864868\n",
       " 2018-01-08  189.742249\n",
       " ...                ...\n",
       " 2019-12-23  245.604355\n",
       " 2019-12-24  246.502350\n",
       " 2019-12-26  246.565201\n",
       " 2019-12-27  247.858337\n",
       " 2019-12-30  249.151474\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker           EVRG\n",
       " Date                 \n",
       " 2018-01-02  40.984604\n",
       " 2018-01-03  40.352169\n",
       " 2018-01-04  40.182503\n",
       " 2018-01-05  39.843147\n",
       " 2018-01-08  39.889408\n",
       " ...               ...\n",
       " 2019-12-23  52.422512\n",
       " 2019-12-24  52.767612\n",
       " 2019-12-26  52.627941\n",
       " 2019-12-27  52.644371\n",
       " 2019-12-30  52.775837\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            EXR\n",
       " Date                 \n",
       " 2018-01-02  66.658241\n",
       " 2018-01-03  66.798286\n",
       " 2018-01-04  65.584595\n",
       " 2018-01-05  65.273407\n",
       " 2018-01-08  66.261459\n",
       " ...               ...\n",
       " 2019-12-23  86.588333\n",
       " 2019-12-24  87.088837\n",
       " 2019-12-26  87.255669\n",
       " 2019-12-27  87.180618\n",
       " 2019-12-30  87.022125\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             FRT\n",
       " Date                  \n",
       " 2018-01-02  101.578720\n",
       " 2018-01-03  101.198997\n",
       " 2018-01-04   97.621887\n",
       " 2018-01-05   97.485191\n",
       " 2018-01-08   98.662361\n",
       " ...                ...\n",
       " 2019-12-23  102.082565\n",
       " 2019-12-24  101.986168\n",
       " 2019-12-26  102.428108\n",
       " 2019-12-27  102.974510\n",
       " 2019-12-30  103.223625\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker           FTNT\n",
       " Date                 \n",
       " 2018-01-02   8.870000\n",
       " 2018-01-03   9.006000\n",
       " 2018-01-04   8.800000\n",
       " 2018-01-05   8.820000\n",
       " 2018-01-08   9.000000\n",
       " ...               ...\n",
       " 2019-12-23  21.563999\n",
       " 2019-12-24  21.556000\n",
       " 2019-12-26  21.648001\n",
       " 2019-12-27  21.490000\n",
       " 2019-12-30  21.389999\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            FTV\n",
       " Date                 \n",
       " 2018-01-02  58.892426\n",
       " 2018-01-03  58.924969\n",
       " 2018-01-04  60.413963\n",
       " 2018-01-05  59.722363\n",
       " 2018-01-08  59.600296\n",
       " ...               ...\n",
       " 2019-12-23  62.991638\n",
       " 2019-12-24  62.614578\n",
       " 2019-12-26  62.532612\n",
       " 2019-12-27  62.770321\n",
       " 2019-12-30  62.524410\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker           FOXA\n",
       " Date                 \n",
       " 2019-03-12  34.927277\n",
       " 2019-03-13  36.535770\n",
       " 2019-03-14  37.362995\n",
       " 2019-03-15  38.328094\n",
       " 2019-03-18  38.328094\n",
       " ...               ...\n",
       " 2019-12-23  34.885117\n",
       " 2019-12-24  34.740749\n",
       " 2019-12-26  34.992218\n",
       " 2019-12-27  34.843201\n",
       " 2019-12-30  34.535843\n",
       " \n",
       " [204 rows x 1 columns],\n",
       " Ticker            FOX\n",
       " Date                 \n",
       " 2019-03-13  35.857578\n",
       " 2019-03-14  36.552780\n",
       " 2019-03-15  37.522396\n",
       " 2019-03-18  37.376034\n",
       " 2019-03-19  36.177742\n",
       " ...               ...\n",
       " 2019-12-23  33.958370\n",
       " 2019-12-24  33.837852\n",
       " 2019-12-26  34.115971\n",
       " 2019-12-27  34.046444\n",
       " 2019-12-30  33.782230\n",
       " \n",
       " [203 rows x 1 columns],\n",
       " Ticker              IT\n",
       " Date                  \n",
       " 2018-01-02  124.849998\n",
       " 2018-01-03  125.190002\n",
       " 2018-01-04  127.300003\n",
       " 2018-01-05  129.339996\n",
       " 2018-01-08  130.309998\n",
       " ...                ...\n",
       " 2019-12-23  153.470001\n",
       " 2019-12-24  153.600006\n",
       " 2019-12-26  154.029999\n",
       " 2019-12-27  153.820007\n",
       " 2019-12-30  152.770004\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             GPN\n",
       " Date                  \n",
       " 2018-01-02   95.881050\n",
       " 2018-01-03   97.951561\n",
       " 2018-01-04   99.819893\n",
       " 2018-01-05   99.733231\n",
       " 2018-01-08  100.330322\n",
       " ...                ...\n",
       " 2019-12-23  175.816147\n",
       " 2019-12-24  176.375641\n",
       " 2019-12-26  177.002686\n",
       " 2019-12-27  176.423843\n",
       " 2019-12-30  174.938324\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             HCA\n",
       " Date                  \n",
       " 2018-01-02   83.828575\n",
       " 2018-01-03   81.515320\n",
       " 2018-01-04   80.503876\n",
       " 2018-01-05   81.412308\n",
       " 2018-01-08   81.243736\n",
       " ...                ...\n",
       " 2019-12-23  142.732422\n",
       " 2019-12-24  141.984055\n",
       " 2019-12-26  142.262268\n",
       " 2019-12-27  143.212158\n",
       " 2019-12-30  141.571457\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker           HSIC\n",
       " Date                 \n",
       " 2018-01-02  56.054901\n",
       " 2018-01-03  56.580391\n",
       " 2018-01-04  56.611767\n",
       " 2018-01-05  57.513725\n",
       " 2018-01-08  58.305882\n",
       " ...               ...\n",
       " 2019-12-23  66.379997\n",
       " 2019-12-24  66.529999\n",
       " 2019-12-26  66.269997\n",
       " 2019-12-27  66.580002\n",
       " 2019-12-30  66.440002\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            HPE\n",
       " Date                 \n",
       " 2018-01-02  11.713598\n",
       " 2018-01-03  11.785754\n",
       " 2018-01-04  12.074389\n",
       " 2018-01-05  12.066371\n",
       " 2018-01-08  11.881964\n",
       " ...               ...\n",
       " 2019-12-23  13.430901\n",
       " 2019-12-24  13.498734\n",
       " 2019-12-26  13.532648\n",
       " 2019-12-27  13.481776\n",
       " 2019-12-30  13.380023\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             HLT\n",
       " Date                  \n",
       " 2018-01-02   77.641930\n",
       " 2018-01-03   78.781998\n",
       " 2018-01-04   78.197365\n",
       " 2018-01-05   77.261917\n",
       " 2018-01-08   78.869713\n",
       " ...                ...\n",
       " 2019-12-23  109.984108\n",
       " 2019-12-24  110.073067\n",
       " 2019-12-26  110.636429\n",
       " 2019-12-27  111.081192\n",
       " 2019-12-30  110.073067\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker           HOLX\n",
       " Date                 \n",
       " 2018-01-02  42.869999\n",
       " 2018-01-03  43.490002\n",
       " 2018-01-04  43.770000\n",
       " 2018-01-05  43.980000\n",
       " 2018-01-08  44.419998\n",
       " ...               ...\n",
       " 2019-12-23  52.560001\n",
       " 2019-12-24  52.590000\n",
       " 2019-12-26  52.340000\n",
       " 2019-12-27  52.360001\n",
       " 2019-12-30  51.860001\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            HWM\n",
       " Date                 \n",
       " 2018-01-02  27.033356\n",
       " 2018-01-03  27.247595\n",
       " 2018-01-04  28.552517\n",
       " 2018-01-05  28.834929\n",
       " 2018-01-08  28.981007\n",
       " ...               ...\n",
       " 2019-12-23  31.171852\n",
       " 2019-12-24  30.954353\n",
       " 2019-12-26  30.845602\n",
       " 2019-12-27  30.786285\n",
       " 2019-12-30  30.519356\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             HII\n",
       " Date                  \n",
       " 2018-01-02  197.828674\n",
       " 2018-01-03  199.026001\n",
       " 2018-01-04  201.863190\n",
       " 2018-01-05  202.808884\n",
       " 2018-01-08  204.795746\n",
       " ...                ...\n",
       " 2019-12-23  228.244949\n",
       " 2019-12-24  226.904922\n",
       " 2019-12-26  225.663116\n",
       " 2019-12-27  224.296280\n",
       " 2019-12-30  224.957367\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             IEX\n",
       " Date                  \n",
       " 2018-01-02  121.183731\n",
       " 2018-01-03  122.278885\n",
       " 2018-01-04  124.239082\n",
       " 2018-01-05  123.999847\n",
       " 2018-01-08  124.211517\n",
       " ...                ...\n",
       " 2019-12-23  163.523544\n",
       " 2019-12-24  162.136948\n",
       " 2019-12-26  162.929306\n",
       " 2019-12-27  162.825500\n",
       " 2019-12-30  162.552032\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            IDXX\n",
       " Date                  \n",
       " 2018-01-02  157.809998\n",
       " 2018-01-03  162.050003\n",
       " 2018-01-04  163.960007\n",
       " 2018-01-05  166.600006\n",
       " 2018-01-08  165.080002\n",
       " ...                ...\n",
       " 2019-12-23  263.980011\n",
       " 2019-12-24  263.260010\n",
       " 2019-12-26  261.429993\n",
       " 2019-12-27  263.980011\n",
       " 2019-12-30  261.600006\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            INCY\n",
       " Date                  \n",
       " 2018-01-02  100.889999\n",
       " 2018-01-03  100.980003\n",
       " 2018-01-04   98.440002\n",
       " 2018-01-05   99.849998\n",
       " 2018-01-08  100.809998\n",
       " ...                ...\n",
       " 2019-12-23   90.160004\n",
       " 2019-12-24   91.430000\n",
       " 2019-12-26   88.790001\n",
       " 2019-12-27   88.389999\n",
       " 2019-12-30   88.050003\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             IQV\n",
       " Date                  \n",
       " 2018-01-02   99.760002\n",
       " 2018-01-03   99.519997\n",
       " 2018-01-04   97.279999\n",
       " 2018-01-05   98.559998\n",
       " 2018-01-08   98.599998\n",
       " ...                ...\n",
       " 2019-12-23  154.869995\n",
       " 2019-12-24  154.699997\n",
       " 2019-12-26  154.139999\n",
       " 2019-12-27  154.440002\n",
       " 2019-12-30  153.449997\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            JBHT\n",
       " Date                  \n",
       " 2018-01-02  109.108757\n",
       " 2018-01-03  109.841858\n",
       " 2018-01-04  109.860672\n",
       " 2018-01-05  109.277931\n",
       " 2018-01-08  110.932098\n",
       " ...                ...\n",
       " 2019-12-23  111.402184\n",
       " 2019-12-24  111.564896\n",
       " 2019-12-26  111.746773\n",
       " 2019-12-27  111.679771\n",
       " 2019-12-30  111.584068\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            JKHY\n",
       " Date                  \n",
       " 2018-01-02  107.114571\n",
       " 2018-01-03  107.252853\n",
       " 2018-01-04  109.373192\n",
       " 2018-01-05  110.424164\n",
       " 2018-01-08  110.461044\n",
       " ...                ...\n",
       " 2019-12-23  137.943314\n",
       " 2019-12-24  138.037521\n",
       " 2019-12-26  137.745300\n",
       " 2019-12-27  138.216690\n",
       " 2019-12-30  137.066544\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            KEYS\n",
       " Date                  \n",
       " 2018-01-02   42.150002\n",
       " 2018-01-03   42.750000\n",
       " 2018-01-04   42.959999\n",
       " 2018-01-05   43.919998\n",
       " 2018-01-08   44.570000\n",
       " ...                ...\n",
       " 2019-12-23  103.959999\n",
       " 2019-12-24  103.220001\n",
       " 2019-12-26  103.650002\n",
       " 2019-12-27  103.230003\n",
       " 2019-12-30  102.180000\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            KHC\n",
       " Date                 \n",
       " 2018-01-02  55.698635\n",
       " 2018-01-03  55.691425\n",
       " 2018-01-04  56.342251\n",
       " 2018-01-05  56.291641\n",
       " 2018-01-08  56.754475\n",
       " ...               ...\n",
       " 2019-12-23  25.423252\n",
       " 2019-12-24  25.471035\n",
       " 2019-12-26  25.192274\n",
       " 2019-12-27  25.184309\n",
       " 2019-12-30  25.255993\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             LW\n",
       " Date                 \n",
       " 2018-01-02  50.454533\n",
       " 2018-01-03  51.083279\n",
       " 2018-01-04  52.140308\n",
       " 2018-01-05  52.577694\n",
       " 2018-01-08  53.361355\n",
       " ...               ...\n",
       " 2019-12-23  79.691689\n",
       " 2019-12-24  79.356155\n",
       " 2019-12-26  80.297539\n",
       " 2019-12-27  80.222977\n",
       " 2019-12-30  79.645081\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            LVS\n",
       " Date                 \n",
       " 2018-01-02  60.021595\n",
       " 2018-01-03  59.344063\n",
       " 2018-01-04  59.196388\n",
       " 2018-01-05  58.996616\n",
       " 2018-01-08  59.066113\n",
       " ...               ...\n",
       " 2019-12-23  66.381409\n",
       " 2019-12-24  66.257103\n",
       " 2019-12-26  66.878647\n",
       " 2019-12-27  66.687401\n",
       " 2019-12-30  66.266663\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker           LDOS\n",
       " Date                 \n",
       " 2018-01-02  57.550766\n",
       " 2018-01-03  57.478821\n",
       " 2018-01-04  58.270149\n",
       " 2018-01-05  58.207211\n",
       " 2018-01-08  59.690926\n",
       " ...               ...\n",
       " 2019-12-23  91.244514\n",
       " 2019-12-24  91.440407\n",
       " 2019-12-26  91.906792\n",
       " 2019-12-27  91.626968\n",
       " 2019-12-30  91.477707\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            LYV\n",
       " Date                 \n",
       " 2018-01-02  42.650002\n",
       " 2018-01-03  42.509998\n",
       " 2018-01-04  42.270000\n",
       " 2018-01-05  43.320000\n",
       " 2018-01-08  43.049999\n",
       " ...               ...\n",
       " 2019-12-23  70.440002\n",
       " 2019-12-24  70.610001\n",
       " 2019-12-26  71.540001\n",
       " 2019-12-27  71.650002\n",
       " 2019-12-30  71.209999\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            LKQ\n",
       " Date                 \n",
       " 2018-01-02  38.402306\n",
       " 2018-01-03  38.597340\n",
       " 2018-01-04  39.061691\n",
       " 2018-01-05  39.024544\n",
       " 2018-01-08  38.875954\n",
       " ...               ...\n",
       " 2019-12-23  33.238663\n",
       " 2019-12-24  33.331535\n",
       " 2019-12-26  33.331535\n",
       " 2019-12-27  33.312962\n",
       " 2019-12-30  33.155079\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            MKTX\n",
       " Date                  \n",
       " 2018-01-02  191.882660\n",
       " 2018-01-03  189.347839\n",
       " 2018-01-04  194.624771\n",
       " 2018-01-05  195.274979\n",
       " 2018-01-08  195.444611\n",
       " ...                ...\n",
       " 2019-12-23  355.390564\n",
       " 2019-12-24  357.993591\n",
       " 2019-12-26  359.926788\n",
       " 2019-12-27  358.874084\n",
       " 2019-12-30  358.395538\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             MTD\n",
       " Date                  \n",
       " 2018-01-02  626.099976\n",
       " 2018-01-03  631.539978\n",
       " 2018-01-04  627.030029\n",
       " 2018-01-05  637.349976\n",
       " 2018-01-08  633.179993\n",
       " ...                ...\n",
       " 2019-12-23  789.429993\n",
       " 2019-12-24  790.469971\n",
       " 2019-12-26  791.979980\n",
       " 2019-12-27  792.830017\n",
       " 2019-12-30  791.909973\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            MGM\n",
       " Date                 \n",
       " 2018-01-02  32.103840\n",
       " 2018-01-03  31.931398\n",
       " 2018-01-04  32.247547\n",
       " 2018-01-05  32.467896\n",
       " 2018-01-08  31.711050\n",
       " ...               ...\n",
       " 2019-12-23  33.211060\n",
       " 2019-12-24  33.141636\n",
       " 2019-12-26  33.250721\n",
       " 2019-12-27  33.310223\n",
       " 2019-12-30  33.042477\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             MAA\n",
       " Date                  \n",
       " 2018-01-02   78.452980\n",
       " 2018-01-03   78.366356\n",
       " 2018-01-04   76.074226\n",
       " 2018-01-05   75.735512\n",
       " 2018-01-08   75.995445\n",
       " ...                ...\n",
       " 2019-12-23  109.299400\n",
       " 2019-12-24  109.570465\n",
       " 2019-12-26  109.629768\n",
       " 2019-12-27  110.112572\n",
       " 2019-12-30  110.578430\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            MSCI\n",
       " Date                  \n",
       " 2018-01-02  118.933769\n",
       " 2018-01-03  120.740860\n",
       " 2018-01-04  122.641121\n",
       " 2018-01-05  123.917274\n",
       " 2018-01-08  124.084946\n",
       " ...                ...\n",
       " 2019-12-23  246.864960\n",
       " 2019-12-24  248.429855\n",
       " 2019-12-26  248.544327\n",
       " 2019-12-27  248.076813\n",
       " 2019-12-30  245.147430\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            NWS\n",
       " Date                 \n",
       " 2018-01-02  15.485758\n",
       " 2018-01-03  15.577934\n",
       " 2018-01-04  15.605590\n",
       " 2018-01-05  15.854468\n",
       " 2018-01-08  15.854468\n",
       " ...               ...\n",
       " 2019-12-23  13.565107\n",
       " 2019-12-24  13.546148\n",
       " 2019-12-26  13.773657\n",
       " 2019-12-27  13.716779\n",
       " 2019-12-30  13.707300\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker           NCLH\n",
       " Date                 \n",
       " 2018-01-02  54.959999\n",
       " 2018-01-03  55.369999\n",
       " 2018-01-04  54.680000\n",
       " 2018-01-05  54.869999\n",
       " 2018-01-08  54.660000\n",
       " ...               ...\n",
       " 2019-12-23  58.509998\n",
       " 2019-12-24  58.380001\n",
       " 2019-12-26  59.110001\n",
       " 2019-12-27  59.110001\n",
       " 2019-12-30  58.590000\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker              NVR\n",
       " Date                   \n",
       " 2018-01-02  3529.610107\n",
       " 2018-01-03  3562.830078\n",
       " 2018-01-04  3520.510010\n",
       " 2018-01-05  3567.000000\n",
       " 2018-01-08  3624.800049\n",
       " ...                 ...\n",
       " 2019-12-23  3786.709961\n",
       " 2019-12-24  3817.149902\n",
       " 2019-12-26  3810.550049\n",
       " 2019-12-27  3816.370117\n",
       " 2019-12-30  3823.000000\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker           ODFL\n",
       " Date                 \n",
       " 2018-01-02  43.566059\n",
       " 2018-01-03  43.611423\n",
       " 2018-01-04  43.867432\n",
       " 2018-01-05  44.266018\n",
       " 2018-01-08  44.706749\n",
       " ...               ...\n",
       " 2019-12-23  61.197102\n",
       " 2019-12-24  61.409428\n",
       " 2019-12-26  61.494366\n",
       " 2019-12-27  61.716484\n",
       " 2019-12-30  61.549889\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             PKG\n",
       " Date                  \n",
       " 2018-01-02   99.750526\n",
       " 2018-01-03  101.663055\n",
       " 2018-01-04  103.357719\n",
       " 2018-01-05  103.672432\n",
       " 2018-01-08  104.568176\n",
       " ...                ...\n",
       " 2019-12-23   96.660957\n",
       " 2019-12-24   96.002518\n",
       " 2019-12-26   95.968346\n",
       " 2019-12-27   95.574959\n",
       " 2019-12-30   95.532211\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            PYPL\n",
       " Date                  \n",
       " 2018-01-02   73.839996\n",
       " 2018-01-03   76.750000\n",
       " 2018-01-04   76.730003\n",
       " 2018-01-05   78.699997\n",
       " 2018-01-08   79.050003\n",
       " ...                ...\n",
       " 2019-12-23  108.610001\n",
       " 2019-12-24  108.690002\n",
       " 2019-12-26  109.750000\n",
       " 2019-12-27  109.400002\n",
       " 2019-12-30  107.970001\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            RJF\n",
       " Date                 \n",
       " 2018-01-02  53.151894\n",
       " 2018-01-03  53.714157\n",
       " 2018-01-04  54.156788\n",
       " 2018-01-05  54.402027\n",
       " 2018-01-08  54.844662\n",
       " ...               ...\n",
       " 2019-12-23  55.546692\n",
       " 2019-12-24  55.405434\n",
       " 2019-12-26  55.712521\n",
       " 2019-12-27  55.460701\n",
       " 2019-12-30  55.319450\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker              O\n",
       " Date                 \n",
       " 2018-01-02  39.565426\n",
       " 2018-01-03  39.460594\n",
       " 2018-01-04  38.608074\n",
       " 2018-01-05  38.580124\n",
       " 2018-01-08  38.629047\n",
       " ...               ...\n",
       " 2019-12-23  54.578751\n",
       " 2019-12-24  54.889748\n",
       " 2019-12-26  55.253864\n",
       " 2019-12-27  55.564896\n",
       " 2019-12-30  55.564896\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            REG\n",
       " Date                 \n",
       " 2018-01-02  52.297771\n",
       " 2018-01-03  51.929276\n",
       " 2018-01-04  50.229637\n",
       " 2018-01-05  50.214577\n",
       " 2018-01-08  50.628223\n",
       " ...               ...\n",
       " 2019-12-23  50.085255\n",
       " 2019-12-24  50.028656\n",
       " 2019-12-26  50.133770\n",
       " 2019-12-27  50.505730\n",
       " 2019-12-30  50.457218\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             RMD\n",
       " Date                  \n",
       " 2018-01-02   79.799202\n",
       " 2018-01-03   80.629562\n",
       " 2018-01-04   80.741539\n",
       " 2018-01-05   81.814491\n",
       " 2018-01-08   82.280960\n",
       " ...                ...\n",
       " 2019-12-23  149.236603\n",
       " 2019-12-24  150.204742\n",
       " 2019-12-26  149.332489\n",
       " 2019-12-27  149.725449\n",
       " 2019-12-30  148.182220\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            ROL\n",
       " Date                 \n",
       " 2018-01-02  19.049898\n",
       " 2018-01-03  18.980484\n",
       " 2018-01-04  19.335756\n",
       " 2018-01-05  19.237747\n",
       " 2018-01-08  19.429678\n",
       " ...               ...\n",
       " 2019-12-23  20.947392\n",
       " 2019-12-24  20.696379\n",
       " 2019-12-26  20.608521\n",
       " 2019-12-27  20.495564\n",
       " 2019-12-30  20.633621\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            SBAC\n",
       " Date                  \n",
       " 2018-01-02  151.431046\n",
       " 2018-01-03  153.325958\n",
       " 2018-01-04  152.486908\n",
       " 2018-01-05  153.542816\n",
       " 2018-01-08  153.561646\n",
       " ...                ...\n",
       " 2019-12-23  227.498688\n",
       " 2019-12-24  227.063736\n",
       " 2019-12-26  228.113266\n",
       " 2019-12-27  228.255081\n",
       " 2019-12-30  225.494202\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            SRE\n",
       " Date                 \n",
       " 2018-01-02  42.118275\n",
       " 2018-01-03  43.233696\n",
       " 2018-01-04  42.945850\n",
       " 2018-01-05  43.357632\n",
       " 2018-01-08  43.369629\n",
       " ...               ...\n",
       " 2019-12-23  63.521839\n",
       " 2019-12-24  63.559811\n",
       " 2019-12-26  63.969059\n",
       " 2019-12-27  64.061615\n",
       " 2019-12-30  64.138054\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             NOW\n",
       " Date                  \n",
       " 2018-01-02  131.729996\n",
       " 2018-01-03  132.910004\n",
       " 2018-01-04  133.850006\n",
       " 2018-01-05  135.009995\n",
       " 2018-01-08  135.300003\n",
       " ...                ...\n",
       " 2019-12-23  283.309998\n",
       " 2019-12-24  284.200012\n",
       " 2019-12-26  286.200012\n",
       " 2019-12-27  286.880005\n",
       " 2019-12-30  282.809998\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            SWKS\n",
       " Date                  \n",
       " 2018-01-02   85.656998\n",
       " 2018-01-03   86.962357\n",
       " 2018-01-04   87.693359\n",
       " 2018-01-05   88.093651\n",
       " 2018-01-08   88.111069\n",
       " ...                ...\n",
       " 2019-12-23  108.300728\n",
       " 2019-12-24  110.222580\n",
       " 2019-12-26  110.330841\n",
       " 2019-12-27  110.339874\n",
       " 2019-12-30  109.202995\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             STE\n",
       " Date                  \n",
       " 2018-01-02   82.516327\n",
       " 2018-01-03   81.423111\n",
       " 2018-01-04   80.909195\n",
       " 2018-01-05   81.245583\n",
       " 2018-01-08   82.983528\n",
       " ...                ...\n",
       " 2019-12-23  144.728729\n",
       " 2019-12-24  145.254257\n",
       " 2019-12-26  144.604507\n",
       " 2019-12-27  145.044022\n",
       " 2019-12-30  145.168274\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            SYF\n",
       " Date                 \n",
       " 2018-01-02  32.421963\n",
       " 2018-01-03  32.638882\n",
       " 2018-01-04  32.872505\n",
       " 2018-01-05  33.156170\n",
       " 2018-01-08  32.755688\n",
       " ...               ...\n",
       " 2019-12-23  31.813038\n",
       " 2019-12-24  31.804279\n",
       " 2019-12-26  31.751740\n",
       " 2019-12-27  31.778011\n",
       " 2019-12-30  31.567846\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            SNPS\n",
       " Date                  \n",
       " 2018-01-02   86.029999\n",
       " 2018-01-03   87.059998\n",
       " 2018-01-04   87.889999\n",
       " 2018-01-05   88.930000\n",
       " 2018-01-08   89.760002\n",
       " ...                ...\n",
       " 2019-12-23  139.910004\n",
       " 2019-12-24  138.210007\n",
       " 2019-12-26  140.070007\n",
       " 2019-12-27  140.619995\n",
       " 2019-12-30  139.100006\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker           TMUS\n",
       " Date                 \n",
       " 2018-01-02  62.834694\n",
       " 2018-01-03  62.412785\n",
       " 2018-01-04  61.814270\n",
       " 2018-01-05  63.384155\n",
       " 2018-01-08  63.874748\n",
       " ...               ...\n",
       " 2019-12-23  75.511520\n",
       " 2019-12-24  75.864746\n",
       " 2019-12-26  75.943245\n",
       " 2019-12-27  75.786247\n",
       " 2019-12-30  76.610443\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            TROW\n",
       " Date                  \n",
       " 2018-01-02   80.215660\n",
       " 2018-01-03   81.312912\n",
       " 2018-01-04   81.951035\n",
       " 2018-01-05   83.445168\n",
       " 2018-01-08   85.507347\n",
       " ...                ...\n",
       " 2019-12-23   99.756325\n",
       " 2019-12-24  100.232056\n",
       " 2019-12-26  100.781631\n",
       " 2019-12-27  100.740623\n",
       " 2019-12-30   99.912178\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            TTWO\n",
       " Date                  \n",
       " 2018-01-02  112.879997\n",
       " 2018-01-03  113.879997\n",
       " 2018-01-04  114.019997\n",
       " 2018-01-05  116.910004\n",
       " 2018-01-08  117.370003\n",
       " ...                ...\n",
       " 2019-12-23  122.120003\n",
       " 2019-12-24  123.930000\n",
       " 2019-12-26  123.989998\n",
       " 2019-12-27  124.470001\n",
       " 2019-12-30  122.349998\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             TFX\n",
       " Date                  \n",
       " 2018-01-02  246.031036\n",
       " 2018-01-03  247.875732\n",
       " 2018-01-04  245.335617\n",
       " 2018-01-05  248.928604\n",
       " 2018-01-08  249.846115\n",
       " ...                ...\n",
       " 2019-12-23  365.046204\n",
       " 2019-12-24  364.724335\n",
       " 2019-12-26  363.544281\n",
       " 2019-12-27  362.773895\n",
       " 2019-12-30  362.198425\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             TDG\n",
       " Date                  \n",
       " 2018-01-02  218.230499\n",
       " 2018-01-03  214.351501\n",
       " 2018-01-04  216.429825\n",
       " 2018-01-05  218.071838\n",
       " 2018-01-08  218.952332\n",
       " ...                ...\n",
       " 2019-12-23  498.143372\n",
       " 2019-12-24  497.807281\n",
       " 2019-12-26  502.133331\n",
       " 2019-12-27  500.978516\n",
       " 2019-12-30  499.228607\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            UDR\n",
       " Date                 \n",
       " 2018-01-02  29.372076\n",
       " 2018-01-03  29.588146\n",
       " 2018-01-04  28.986200\n",
       " 2018-01-05  28.947609\n",
       " 2018-01-08  29.024784\n",
       " ...               ...\n",
       " 2019-12-23  37.736778\n",
       " 2019-12-24  37.893105\n",
       " 2019-12-26  38.016548\n",
       " 2019-12-27  38.131741\n",
       " 2019-12-30  38.123508\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            ULTA\n",
       " Date                  \n",
       " 2018-01-02  229.630005\n",
       " 2018-01-03  245.119995\n",
       " 2018-01-04  244.880005\n",
       " 2018-01-05  237.960007\n",
       " 2018-01-08  231.139999\n",
       " ...                ...\n",
       " 2019-12-23  253.020004\n",
       " 2019-12-24  252.490005\n",
       " 2019-12-26  251.330002\n",
       " 2019-12-27  253.169998\n",
       " 2019-12-30  251.350006\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            UAL\n",
       " Date                 \n",
       " 2018-01-02  68.940002\n",
       " 2018-01-03  68.489998\n",
       " 2018-01-04  69.260002\n",
       " 2018-01-05  69.360001\n",
       " 2018-01-08  68.510002\n",
       " ...               ...\n",
       " 2019-12-23  89.440002\n",
       " 2019-12-24  89.150002\n",
       " 2019-12-26  89.260002\n",
       " 2019-12-27  88.370003\n",
       " 2019-12-30  87.959999\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            VRSK\n",
       " Date                  \n",
       " 2018-01-02   92.212692\n",
       " 2018-01-03   91.943260\n",
       " 2018-01-04   92.405121\n",
       " 2018-01-05   93.223038\n",
       " 2018-01-08   93.338501\n",
       " ...                ...\n",
       " 2019-12-23  144.912170\n",
       " 2019-12-24  144.543930\n",
       " 2019-12-26  144.214462\n",
       " 2019-12-27  143.972260\n",
       " 2019-12-30  142.974182\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            WRB\n",
       " Date                 \n",
       " 2018-01-02  17.818491\n",
       " 2018-01-03  17.670944\n",
       " 2018-01-04  17.742168\n",
       " 2018-01-05  17.668392\n",
       " 2018-01-08  17.579348\n",
       " ...               ...\n",
       " 2019-12-23  27.492758\n",
       " 2019-12-24  27.500795\n",
       " 2019-12-26  27.520893\n",
       " 2019-12-27  27.561087\n",
       " 2019-12-30  27.585203\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            WAB\n",
       " Date                 \n",
       " 2018-01-02  79.478287\n",
       " 2018-01-03  78.836174\n",
       " 2018-01-04  79.899979\n",
       " 2018-01-05  78.424080\n",
       " 2018-01-08  78.941612\n",
       " ...               ...\n",
       " 2019-12-23  75.511505\n",
       " 2019-12-24  75.288422\n",
       " 2019-12-26  75.821831\n",
       " 2019-12-27  76.180702\n",
       " 2019-12-30  75.259361\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker             WTW\n",
       " Date                  \n",
       " 2018-01-02  133.155457\n",
       " 2018-01-03  135.646622\n",
       " 2018-01-04  137.023560\n",
       " 2018-01-05  137.902206\n",
       " 2018-01-08  137.159439\n",
       " ...                ...\n",
       " 2019-12-23  187.544495\n",
       " 2019-12-24  187.926010\n",
       " 2019-12-26  187.953888\n",
       " 2019-12-27  187.711975\n",
       " 2019-12-30  188.150665\n",
       " \n",
       " [502 rows x 1 columns],\n",
       " Ticker            ZBRA\n",
       " Date                  \n",
       " 2018-01-02  103.709999\n",
       " 2018-01-03  105.769997\n",
       " 2018-01-04  107.860001\n",
       " 2018-01-05  109.540001\n",
       " 2018-01-08  110.629997\n",
       " ...                ...\n",
       " 2019-12-23  256.730011\n",
       " 2019-12-24  254.330002\n",
       " 2019-12-26  254.419998\n",
       " 2019-12-27  256.000000\n",
       " 2019-12-30  254.110001\n",
       " \n",
       " [502 rows x 1 columns]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AOS</th>\n",
       "      <th>AMD</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ARE</th>\n",
       "      <th>ALGN</th>\n",
       "      <th>LNT</th>\n",
       "      <th>AMCR</th>\n",
       "      <th>AWK</th>\n",
       "      <th>ANSS</th>\n",
       "      <th>ANET</th>\n",
       "      <th>...</th>\n",
       "      <th>TFX</th>\n",
       "      <th>TDG</th>\n",
       "      <th>UDR</th>\n",
       "      <th>ULTA</th>\n",
       "      <th>UAL</th>\n",
       "      <th>VRSK</th>\n",
       "      <th>WRB</th>\n",
       "      <th>WAB</th>\n",
       "      <th>WTW</th>\n",
       "      <th>ZBRA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AOS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.393238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.491568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.280736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.265877</td>\n",
       "      <td>0.274042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339619</td>\n",
       "      <td>0.232805</td>\n",
       "      <td>0.247517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.317796</td>\n",
       "      <td>0.258112</td>\n",
       "      <td>0.271942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344796</td>\n",
       "      <td>0.235556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>0.393238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.280736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.167007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.161193</td>\n",
       "      <td>0.203542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219604</td>\n",
       "      <td>0.131363</td>\n",
       "      <td>0.211723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.468665</td>\n",
       "      <td>0.211035</td>\n",
       "      <td>0.164974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193568</td>\n",
       "      <td>0.264387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALGN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.363642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRSK</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.211035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.153299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.127465</td>\n",
       "      <td>0.292239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259143</td>\n",
       "      <td>0.177131</td>\n",
       "      <td>0.170863</td>\n",
       "      <td>0.496662</td>\n",
       "      <td>0.386888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.221460</td>\n",
       "      <td>0.286675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WRB</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.271942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.164974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117768</td>\n",
       "      <td>0.234777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190872</td>\n",
       "      <td>0.136175</td>\n",
       "      <td>0.201737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.433177</td>\n",
       "      <td>0.120301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.183705</td>\n",
       "      <td>0.298412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAB</th>\n",
       "      <td>0.491568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.363642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTW</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.231397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189312</td>\n",
       "      <td>0.271986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167778</td>\n",
       "      <td>0.195977</td>\n",
       "      <td>0.263810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489508</td>\n",
       "      <td>0.221460</td>\n",
       "      <td>0.183705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.319637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.235556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.264387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.256359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.282638</td>\n",
       "      <td>0.298758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343237</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.242702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>0.286675</td>\n",
       "      <td>0.298412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.319637</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker       AOS       AMD       ALB       ARE      ALGN       LNT  AMCR  \\\n",
       "Ticker                                                                     \n",
       "AOS     0.000000       NaN  0.393238       NaN       NaN       NaN   NaN   \n",
       "AMD          NaN  0.000000       NaN  0.280736       NaN  0.244904   NaN   \n",
       "ALB     0.393238       NaN  0.000000       NaN       NaN       NaN   NaN   \n",
       "ARE          NaN  0.280736       NaN  0.000000       NaN  0.167007   NaN   \n",
       "ALGN         NaN       NaN       NaN       NaN  0.000000       NaN   NaN   \n",
       "...          ...       ...       ...       ...       ...       ...   ...   \n",
       "VRSK         NaN  0.258112       NaN  0.211035       NaN  0.153299   NaN   \n",
       "WRB          NaN  0.271942       NaN  0.164974       NaN  0.136098   NaN   \n",
       "WAB     0.491568       NaN  0.454849       NaN  0.363642       NaN   NaN   \n",
       "WTW          NaN  0.344796       NaN  0.193568       NaN  0.231397   NaN   \n",
       "ZBRA         NaN  0.235556       NaN  0.264387       NaN  0.256359   NaN   \n",
       "\n",
       "Ticker       AWK      ANSS  ANET  ...       TFX       TDG       UDR      ULTA  \\\n",
       "Ticker                            ...                                           \n",
       "AOS          NaN       NaN   NaN  ...       NaN       NaN       NaN       NaN   \n",
       "AMD     0.265877  0.274042   NaN  ...  0.339619  0.232805  0.247517       NaN   \n",
       "ALB          NaN       NaN   NaN  ...       NaN       NaN       NaN       NaN   \n",
       "ARE     0.161193  0.203542   NaN  ...  0.219604  0.131363  0.211723       NaN   \n",
       "ALGN         NaN       NaN   NaN  ...       NaN       NaN       NaN       NaN   \n",
       "...          ...       ...   ...  ...       ...       ...       ...       ...   \n",
       "VRSK    0.127465  0.292239   NaN  ...  0.259143  0.177131  0.170863  0.496662   \n",
       "WRB     0.117768  0.234777   NaN  ...  0.190872  0.136175  0.201737       NaN   \n",
       "WAB          NaN       NaN   NaN  ...       NaN       NaN       NaN       NaN   \n",
       "WTW     0.189312  0.271986   NaN  ...  0.167778  0.195977  0.263810       NaN   \n",
       "ZBRA    0.282638  0.298758   NaN  ...  0.343237  0.219700  0.242702       NaN   \n",
       "\n",
       "Ticker       UAL      VRSK       WRB       WAB       WTW      ZBRA  \n",
       "Ticker                                                              \n",
       "AOS          NaN       NaN       NaN  0.491568       NaN       NaN  \n",
       "AMD     0.317796  0.258112  0.271942       NaN  0.344796  0.235556  \n",
       "ALB          NaN       NaN       NaN  0.454849       NaN       NaN  \n",
       "ARE     0.468665  0.211035  0.164974       NaN  0.193568  0.264387  \n",
       "ALGN         NaN       NaN       NaN  0.363642       NaN       NaN  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "VRSK    0.386888  0.000000  0.120301       NaN  0.221460  0.286675  \n",
       "WRB     0.433177  0.120301  0.000000       NaN  0.183705  0.298412  \n",
       "WAB          NaN       NaN       NaN  0.000000       NaN       NaN  \n",
       "WTW     0.489508  0.221460  0.183705       NaN  0.000000  0.319637  \n",
       "ZBRA    0.366298  0.286675  0.298412       NaN  0.319637  0.000000  \n",
       "\n",
       "[98 rows x 98 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data_list[0])\n",
    "for z in data_list[1:]:\n",
    "    z= pd.DataFrame(z)\n",
    "    stock_name = z.columns[0]\n",
    "    data[stock_name] = z[stock_name]\n",
    "Correlation_matrix = data.corr()\n",
    "Angular_distance = np.sqrt((1/2)*(1-Correlation_matrix))\n",
    "angular = Angular_distance[Angular_distance <0.5]\n",
    "angular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to normalize the price \n",
    "value = data.agg(['min','max'])\n",
    "\n",
    "data_norm = (data - value.loc['min']) / (value.loc['max'] - value.loc['min'])\n",
    "\n",
    "data_norm.fillna(method = 'ffill',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to compute the 'euclidian distance' between the prices to find the best pairs.\n",
    "distances = np.zeros((data_norm.shape[1],data_norm.shape[1]))\n",
    "for col in data_norm.columns:\n",
    "    for col2 in data_norm.columns:\n",
    "        distances[data_norm.columns.get_loc(col)][data_norm.columns.get_loc(col2)] = np.sqrt(((data_norm[col] - data_norm[col2])**2).sum())\n",
    "distances = pd.DataFrame(distances, columns=data_norm.columns, index = data_norm.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Generate a custom colormap\n",
    "cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(distances, cmap=cmap, annot=False, fmt=\".1f\", linewidths=.5)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Matrix Plot with Color Coding')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Rows')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So as we can see, it is a bit confusing.\n",
    "# So we are going to go sector neutral by diving our universe with the Gics sector\n",
    "liste_sector = stock_lists['GICS Sector'].unique()\n",
    "liste_by_sector = {i:stock_lists[stock_lists['GICS Sector']==i]['Symbol'] for i in liste_sector}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sector in liste_sector:\n",
    "    l = liste_by_sector[sector]\n",
    "    distances1 = distances.loc[l][l]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Generate a custom colormap\n",
    "    cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap\n",
    "    sns.heatmap(distances1, cmap=cmap, annot=False, fmt=\".1f\", linewidths=.5)\n",
    "\n",
    "# Add titles and labels\n",
    "    plt.title(f'Distances between ticker in ' + sector)\n",
    "    plt.xlabel('Tickers')\n",
    "    plt.ylabel('Tickers')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are going to set some threshold for the rest of the analysis, \n",
    "# We set that we have to take at least one pair by sector to be market neutral \n",
    "# We are then going to find the 9 smallest pair to get 20 paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = {k:[tuple(sorted((i,j))) for i in liste_by_sector[k] for j in liste_by_sector[k] if j!=i] for k in liste_sector}\n",
    "pairs_without_duplicates = {k :sorted(list(set(pairs[k]))) for k in liste_sector}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_sector = 2\n",
    "selected_pairs ={}\n",
    "for sector in liste_sector:\n",
    "    l = liste_by_sector[sector]\n",
    "    distances1 = distances.loc[l][l]\n",
    "    np.fill_diagonal(distances1.values, 1000)\n",
    "    minimum_values = np.unique((np.array(distances1).reshape(-1,1)))\n",
    "    if len(minimum_values) > 2:\n",
    "        minimum_values = minimum_values[nb_sector:nb_sector+1]\n",
    "        distances1 = distances1[distances1<minimum_values[0]]\n",
    "        pair_list = list(distances1[distances1.notna()].stack().index)\n",
    "        pair_list = [tuple(sorted(pair)) for pair in pair_list]\n",
    "        selected_pairs[sector] = [values for values in pairs_without_duplicates[sector] if values in pair_list]\n",
    "    else:\n",
    "        selected_pairs[sector] = pairs_without_duplicates[sector]\n",
    "\n",
    "selected_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have selected our pairs we gonna reduce our initial dataframe to the only couple that we have \n",
    "# We have to create a list from the couples and then reduce the dataframe to this\n",
    "data1 = data_norm.copy()\n",
    "data2 = data.copy()\n",
    "# The goal would be to stock every small data frame in a dictionnay to help doing the steps for the reste \n",
    "dataframes_dictionnary_norm = {}\n",
    "dataframes_dictionnary_raw ={}\n",
    "for sector in liste_sector: \n",
    "    for value in selected_pairs[sector]:\n",
    "        dataframes_dictionnary_norm[value] = data1[list(value)]\n",
    "        dataframes_dictionnary_raw[value] = data2[list(value)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is two approach that we can use for this, the first one would be to be dollar neutral which mean that the spread is simply the difference between the two stocks \n",
    "# The second way to do it is by computing S_a = beta * S_b + alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is time to see a little bit of plotting for each pairs just to have a feeling of what we can do next \n",
    "for key in dataframes_dictionnary_raw:\n",
    "    plt.figure(figsize=(15, 20))\n",
    "    x = dataframes_dictionnary_raw[key].index\n",
    "    y1 = dataframes_dictionnary_raw[key][key[0]]\n",
    "    y2 = dataframes_dictionnary_raw[key][key[1]]\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot on the first y-axis\n",
    "    ax1.plot(x, y1, 'b-', label=f'{key[0]}')\n",
    "    ax1.set_xlabel('Date')  # Common x-axis label\n",
    "    ax1.set_ylabel(f'{key[0]}', color='b')  # First y-axis label\n",
    "    ax1.tick_params(axis='y', labelcolor='b')  # Match tick labels with axis color\n",
    "\n",
    "# Create the second y-axis\n",
    "    ax2 = ax1.twinx()  # This shares the same x-axis\n",
    "    ax2.plot(x, y2, 'r-', label=f'{key[1]}')\n",
    "    ax2.set_ylabel(f'{key[1]}', color='r')  # Second y-axis label\n",
    "    ax2.tick_params(axis='y', labelcolor='r')  # Match tick labels with axis color\n",
    "\n",
    "# Add a legend\n",
    "    fig.legend(loc=\"upper left\", bbox_to_anchor=(0.01, 0.09))\n",
    "\n",
    "# Add a grid (optional)\n",
    "    ax1.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "    plt.title(f\"Plot for the pair ({key[0]},{key[1]})\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to compute the Normalizing pair divergence \n",
    "# Delta_norm = (Delta - MA_10d) / std_10days \n",
    "\n",
    "for key,values in dataframes_dictionnary_raw.items():\n",
    "    values['Delta'] = np.abs(values[key[0]] - values[key[1]])\n",
    "    values['Delta_norm'] = (values['Delta'] - values['Delta'].rolling(10).mean()) / values['Delta'].rolling(10).std()\n",
    "    values.drop(['Delta'], axis = 1, inplace=True )\n",
    "\n",
    "dataframes_dictionnary_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_mean_and_std_values ={key:dataframes_dictionnary_raw[key]['Delta_norm'].agg(['mean','std']) for key in dataframes_dictionnary_raw.keys() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemple = dataframes_dictionnary_raw[('CPRT',\n",
    "  'TDG')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,exemple in dataframes_dictionnary_raw.items():\n",
    "\n",
    "    exemple['Delta_norm']\n",
    "    exemple['mean'] = exemple['Delta_norm'].mean()\n",
    "    z2 = exemple['Delta_norm'].mean() + 1.8* exemple['Delta_norm'].std()\n",
    "    z3 = exemple['Delta_norm'].mean() - 1.8 * exemple['Delta_norm'].std()\n",
    "    exemple['upper_bond'] = z2\n",
    "    exemple['lower_bond'] = z3\n",
    "    exemple['a'] = (exemple['Delta_norm'] > exemple['upper_bond']) *1\n",
    "    exemple['b'] = (exemple['Delta_norm'] < exemple['lower_bond']) *1\n",
    "    exemple[['a','b']] = exemple[['a','b']] - exemple[['a','b']].shift(1) *(1)\n",
    "    exemple['entry_points'] = exemple['a'] + exemple['b']\n",
    "    \n",
    "    plt.figure(figsize=(15, 20))\n",
    "    #exemple = exemple.iloc[:50]\n",
    "    x = exemple.index\n",
    "    y1 = exemple[key[0]]\n",
    "    y2 = exemple[key[1]]\n",
    "    y3 = exemple['Delta_norm']\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot on the first y-axis\n",
    "    ax1.plot(x, y1, 'b-', label=f'{key[0]}')\n",
    "    ax1.set_xlabel('Date')  # Common x-axis label\n",
    "    ax1.set_ylabel(f'{key[0]}', color='b')  # First y-axis label\n",
    "    ax1.tick_params(axis='y', labelcolor='b')  # Match tick labels with axis color\n",
    "\n",
    "# Create the second y-axis\n",
    "    ax2 = ax1.twinx()  # This shares the same x-axis\n",
    "    ax2.plot(x, y2, 'r-', label=f'{key[1]}')\n",
    "    ax2.set_ylabel(f'{key[1]}', color='r')  # Second y-axis label\n",
    "    ax2.tick_params(axis='y', labelcolor='r')  # Match tick labels with axis color\n",
    "\n",
    "    ax3 = ax1.twinx()\n",
    "    ax3.plot(x,y3,'g-')\n",
    "\n",
    "# Add a legend\n",
    "    fig.legend(loc=\"upper left\", bbox_to_anchor=(0.01, 0.09))\n",
    "\n",
    "# Add a grid (optional)\n",
    "    ax1.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "    plt.title(f\"Plot for the pair ({key[0]},{key[1]})\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemple['a'] = (exemple['Delta_norm'] > exemple['upper_bond']) *1\n",
    "exemple['b'] = (exemple['Delta_norm'] < exemple['lower_bond']) *1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemple[['a','b']] = exemple[['a','b']] - exemple[['a','b']].shift(1) *(1)\n",
    "exemple['entry_points'] = exemple['a'] + exemple['b']\n",
    "exemple.drop(['a','b'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemple.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemple.set_index('Date', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = exemple\n",
    "\n",
    "# Reshape the data for plotting\n",
    "df_melted = df.melt(id_vars=['Date', \"a\", \"b\"], value_vars=[\"Delta_norm\", \"lower_bond\", \"upper_bond\",'a'], \n",
    "                    var_name=\"Variable\", value_name=\"Value\")\n",
    "\n",
    "# Create an interactive Plotly line chart\n",
    "fig = px.line(df_melted, \n",
    "              x=\"Date\", \n",
    "              y=\"Value\", \n",
    "              color=\"Variable\", \n",
    "              line_group=\"Variable\",\n",
    "              title=\"Interactive Zoomable Chart\",\n",
    "              markers=True)\n",
    "\n",
    "# Update layout for zoomable x-axis\n",
    "fig.update_layout(xaxis=dict(title=\"Date\", rangeslider=dict(visible=True)), \n",
    "                  yaxis=dict(title=\"Value\"), \n",
    "                  hovermode=\"x unified\")\n",
    "\n",
    "# Show the chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y1 = values['Delta_norm']\n",
    "y2 = values['Delta_norm'].mean() + 2 * values['Delta_norm'].std()\n",
    "y3 = values['Delta_norm'].mean() - 2*values['Delta_norm'].std()\n",
    "values['a'] = [1 if values['Delta_norm'] > y2 else 0] \n",
    "values['b'] = [-1 if values['Delta_norm'] < y3 else 0 ]\n",
    "values['Entry_points'] = values['a'] + values['b']\n",
    "values.drop([['a','b']], inplace = True)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(values.index,y1)\n",
    "ax.plot(values.index,y2)\n",
    "ax.plot(values.index,y3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ornstein_uhlenbeck(\n",
    "    X0=0.0,       # Initial value\n",
    "    theta=0.0,    # Long-term mean\n",
    "    kappa=0.3,    # Speed of mean reversion\n",
    "    sigma=0.3,    # Volatility\n",
    "    T=1.0,        # Total time\n",
    "    N=1000,       # Number of steps\n",
    "    seed=None     # Random seed for reproducibility\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulate an Ornstein-Uhlenbeck process with X as a list.\n",
    "\n",
    "    Parameters:\n",
    "    - X0 (float): Initial value of the process.\n",
    "    - theta (float): Long-term mean.\n",
    "    - kappa (float): Speed of mean reversion.\n",
    "    - sigma (float): Volatility parameter.\n",
    "    - T (float): Total time to simulate.\n",
    "    - N (int): Number of time steps.\n",
    "    - seed (int, optional): Seed for the random number generator.\n",
    "\n",
    "    Returns:\n",
    "    - t (numpy.ndarray): Array of time points.\n",
    "    - X (list of float): Simulated Ornstein-Uhlenbeck process as a list.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    dt = T / N\n",
    "    t = np.linspace(0, T, N+1)\n",
    "    X = [X0]  # Initialize X as a list with the initial value\n",
    "    \n",
    "    # Generate all random shocks at once for efficiency\n",
    "    dW = np.random.normal(scale=np.sqrt(dt), size=N)\n",
    "    \n",
    "    # Simulate the process\n",
    "    for i in range(N):\n",
    "        X_prev = X[-1]\n",
    "        X_new = X_prev + kappa * (theta - X_prev) * dt + sigma * dW[i]\n",
    "        X.append(X_new)\n",
    "    \n",
    "    return t, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,X =ornstein_uhlenbeck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X.mean()\n",
    "std = X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(t,X)\n",
    "plt.axhline(mean +1.2*std, color='green')\n",
    "plt.axhline(mean-1.2*std, color='red')\n",
    "plt.axhline(mean)\n",
    "plt.title('Beta Neutral Spread of the pair with the lowest distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_points = ((X>mean+1.2*std) ^ (X<mean -1.2*std))*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame([t,X,entry_points])\n",
    "df_test =df_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['3'] = df_test[2].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['4'] = (df_test[2]!=df_test['3'])*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['4'][0] =0\n",
    "df_test['5']=df_test['4'].cumsum()\n",
    "df_test['6'] = (df_test['5']!=df_test['5'].shift(1))*df_test['5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['7'] = df_test['6'].apply(\n",
    "    lambda i: np.nan if i == 0 else ('green' if i % 2 == 1 else 'red')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_map = {'green': '^', 'red': 'v'}\n",
    "color_map = {'green': 'green', 'red': 'red'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot X_i vs time as a line\n",
    "ax.plot(df_test[0], df_test[1], label='X_i Value', color='blue', linewidth=2)\n",
    "\n",
    "# Plot upward triangles for 'green'\n",
    "green_points = df_test[df_test['7'] == 'green']\n",
    "ax.scatter(\n",
    "    green_points[0],\n",
    "    green_points[1],\n",
    "    marker=marker_map['green'],\n",
    "    color=color_map['green'],\n",
    "    s=100,  # Marker size\n",
    "    label='Green Marker'\n",
    ")\n",
    "\n",
    "# Plot downward triangles for 'red'\n",
    "red_points = df_test[df_test['7'] == 'red']\n",
    "ax.scatter(\n",
    "    red_points[0],\n",
    "    red_points[1],\n",
    "    marker=marker_map['red'],\n",
    "    color=color_map['red'],\n",
    "    s=100,  # Marker size\n",
    "    label='Red Marker'\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('Time', fontsize=12)\n",
    "ax.set_ylabel('X_i Value', fontsize=12)\n",
    "ax.set_title('X_i Over Time with Conditional Markers', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Tight layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Example stock price movements (replace this with your actual data)\n",
    "data = {\n",
    "    \"Price\": [100, 102, 105, 109, 110,111,107,109,108.5,104, 103, 98, 95, 96, 100, 102, 105,108,110,103,99,98,100]\n",
    "}\n",
    "\n",
    "# Convert data to a DataFrame\n",
    "prices = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the mean and standard deviation\n",
    "mean_price = prices['Price'].mean()\n",
    "std_price= prices['Price'].std()\n",
    "print(mean_price,std_price)\n",
    "# Part 1: Define buy and sell signals based on thresholds\n",
    "#prices['SB'] = 0  # Default: no action\n",
    "\n",
    "\n",
    "# Buy signal (price goes below mean - std)\n",
    "\n",
    "\n",
    "# Sell signal (price goes above mean + std)\n",
    "\"\"\"prices.loc[(prices['Price'] > (mean_price + std_price)), 'SB'] = 1\n",
    "prices['BU'] = ((prices['SB'] - prices['SB'].shift(1))>0)*1\n",
    "prices.drop('SB',axis = 1, inplace = True)\n",
    "prices['SM'] =0\n",
    "prices.loc[(prices['Price'] > mean_price),'SM'] = 1\n",
    "\n",
    "\n",
    "prices['DM'] = ((prices['SM'] - prices['SM'].shift(1)) <0) *-1\n",
    "prices.drop('SM',axis = 1, inplace = True)\n",
    "prices['Final_up_signals'] = prices['BU'] + prices['DM'] \n",
    "prices.drop(['DM','BU'],axis =1, inplace = True )\n",
    "c\n",
    "prices['ON'] = [(acc := min(acc + x, 1)) for x in prices['Final_up_signals']]\n",
    "\n",
    "print(prices)\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(trading_signals(prices,'Price'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, -1,0,0]\n",
    "\n",
    "acc = 0\n",
    "res = []\n",
    "for val in arr:\n",
    "    acc += val\n",
    "    if acc > 1:\n",
    "        acc = 1\n",
    "    # (Optionally, if you also want to ensure it never goes below 0, you could do:\n",
    "    # if acc < 0: \n",
    "    #     acc = 0\n",
    "    # Depending on your exact needs.)\n",
    "    res.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, -1]\n",
    "\n",
    "acc = 0\n",
    "res = [(acc := min(acc + x, 1)) for x in arr]\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "prices.loc[(prices['Price'] < (mean_price - std_price)), 'SS'] = 1\n",
    "prices['SD'] = ((prices['SS'] - prices['SS'].shift(1))>0)*1\n",
    "prices['SM'] =0\n",
    "prices.loc[(prices['Price'] < mean_price),'SM'] = 1\n",
    "\n",
    "prices['U_mean'] = ((prices['SM'] - prices['SM'].shift(1)) >0) *-1\n",
    "prices['Final_d_signals'] = prices['SD'] + prices['U_mean'] \n",
    "\n",
    "# Print the DataFrame with signals and positions\n",
    "print(prices)\n",
    "\n",
    "# Example output:\n",
    "# A DataFrame showing prices, mean, std, signals (1 = buy, -1 = sell), and positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Sample Data\n",
    "# Replace this with your actual data\n",
    "data = {\n",
    "    \"Date\": pd.date_range(start=\"2023-01-01\", periods=100),\n",
    "    \"Pair_A\": [i + (i * 0.05) for i in range(100)],\n",
    "    \"Pair_B\": [i * 1.5 for i in range(100)],\n",
    "    \"Pair_C\": [100 - i * 0.8 for i in range(100)],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize Dash App\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Layout\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Interactive Pair Plot (Using 'go')\"),\n",
    "    html.Div([\n",
    "        html.Label(\"Select Pairs:\"),\n",
    "        dcc.Checklist(\n",
    "            id='pair-selector',\n",
    "            options=[{\"label\": pair, \"value\": pair} for pair in df.columns if pair != \"Date\"],\n",
    "            value=[\"Pair_A\"],\n",
    "            inline=True,\n",
    "        ),\n",
    "    ]),\n",
    "    html.Div([\n",
    "        html.Label(\"Select Time Period:\"),\n",
    "        dcc.DatePickerRange(\n",
    "            id='date-picker',\n",
    "            start_date=df['Date'].min(),\n",
    "            end_date=df['Date'].max(),\n",
    "            display_format=\"YYYY-MM-DD\"\n",
    "        ),\n",
    "    ]),\n",
    "    html.Div([\n",
    "        html.Label(\"Select Plot Type:\"),\n",
    "        dcc.Dropdown(\n",
    "            id='plot-type',\n",
    "            options=[\n",
    "                {\"label\": \"Line Plot\", \"value\": \"line\"},\n",
    "                {\"label\": \"Scatter Plot\", \"value\": \"scatter\"},\n",
    "            ],\n",
    "            value=\"line\",\n",
    "        ),\n",
    "    ]),\n",
    "    dcc.Graph(id='interactive-plot')\n",
    "])\n",
    "\n",
    "# Callbacks\n",
    "@app.callback(\n",
    "    Output('interactive-plot', 'figure'),\n",
    "    [Input('pair-selector', 'value'),\n",
    "     Input('date-picker', 'start_date'),\n",
    "     Input('date-picker', 'end_date'),\n",
    "     Input('plot-type', 'value')]\n",
    ")\n",
    "def update_plot(selected_pairs, start_date, end_date, plot_type):\n",
    "    # Filter data based on selected date range\n",
    "    filtered_df = df[(df['Date'] >= pd.to_datetime(start_date)) & (df['Date'] <= pd.to_datetime(end_date))]\n",
    "    \n",
    "    # Create the figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for pair in selected_pairs:\n",
    "        if plot_type == \"line\":\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=filtered_df['Date'],\n",
    "                y=filtered_df[pair],\n",
    "                mode='lines',\n",
    "                name=pair\n",
    "            ))\n",
    "        elif plot_type == \"scatter\":\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=filtered_df['Date'],\n",
    "                y=filtered_df[pair],\n",
    "                mode='markers',\n",
    "                name=pair\n",
    "            ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=\"Interactive Pair Plot\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Value\",\n",
    "        legend_title=\"Pairs\",\n",
    "        template=\"plotly_dark\",\n",
    "        margin=dict(l=40, r=40, t=40, b=40),\n",
    "        hovermode=\"x unified\"\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Sample data\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y1 = [10, 15, 13, 17, 14]\n",
    "y2 = [16, 18, 11, 9, 12]\n",
    "y3 = [5, 9, 14, 10, 6]\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces for each line\n",
    "fig.add_trace(go.Scatter(x=x, y=y1, mode='lines+markers', name='Plot 1'))\n",
    "fig.add_trace(go.Scatter(x=x, y=y2, mode='lines+markers', name='Plot 2'))\n",
    "fig.add_trace(go.Scatter(x=x, y=y3, mode='lines+markers', name='Plot 3'))\n",
    "\n",
    "# Update layout for better interactivity\n",
    "fig.update_layout(\n",
    "    title=\"Interactive Plot with Multiple Lines\",\n",
    "    xaxis_title=\"X-axis\",\n",
    "    yaxis_title=\"Y-axis\",\n",
    "    hovermode=\"x unified\"\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Generate example stock price paths\n",
    "def generate_stock_path(start_price, days, volatility):\n",
    "    prices = [start_price]\n",
    "    for _ in range(days - 1):\n",
    "        change = np.random.normal(0, volatility)\n",
    "        prices.append(prices[-1] * (1 + change))\n",
    "    return prices\n",
    "\n",
    "# Generate trading signals (random for example)\n",
    "def generate_signals(prices):\n",
    "    signals = []\n",
    "    for i in range(1, len(prices) - 1):\n",
    "        if prices[i - 1] < prices[i] > prices[i + 1]:  # Example: Local maxima as \"entry\"\n",
    "            signals.append(i)\n",
    "    return signals\n",
    "\n",
    "# Parameters\n",
    "num_paths = 3\n",
    "start_price = 100\n",
    "days = 50\n",
    "volatility = 0.02\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Generate stock paths and signals\n",
    "for i in range(num_paths):\n",
    "    prices = generate_stock_path(start_price, days, volatility)\n",
    "    signals = generate_signals(prices)\n",
    "\n",
    "    # Add the stock price path\n",
    "    fig.add_trace(go.Scatter(x=list(range(days)), y=prices, mode='lines', name=f'Stock {i + 1}'))\n",
    "\n",
    "    # Add the trading signals\n",
    "    signal_prices = [prices[j] for j in signals]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=signals, \n",
    "        y=signal_prices, \n",
    "        mode='markers', \n",
    "        name=f'Signals {i + 1}',\n",
    "        marker=dict(size=10, symbol='x', color='red')\n",
    "    ))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title=\"Stock Price Paths with Trading Signals\",\n",
    "    xaxis_title=\"Days\",\n",
    "    yaxis_title=\"Price\",\n",
    "    hovermode=\"x unified\"\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "# Generate stock paths and signals\n",
    "for key,values in data.items():\n",
    "    prices = values['Delta_norm']\n",
    "    up_signals, down_signals = \n",
    "\n",
    "    # Add the stock price path\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=values.index, \n",
    "        y=prices, \n",
    "        mode='lines', \n",
    "        name=f'Stock {i + 1}'\n",
    "    ))\n",
    "\n",
    "    # Add the up signals\n",
    "    up_signal_prices = [prices[j] for j in up_signals]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=up_signals, \n",
    "        y=up_signal_prices, \n",
    "        mode='markers', \n",
    "        name=f'Up Signals {i + 1}',\n",
    "        marker=dict(size=10, symbol='triangle-up', color='green')\n",
    "    ))\n",
    "\n",
    "    # Add the down signals\n",
    "    down_signal_prices = [prices[j] for j in down_signals]\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=down_signals, \n",
    "        y=down_signal_prices, \n",
    "        mode='markers', \n",
    "        name=f'Down Signals {i + 1}',\n",
    "        marker=dict(size=10, symbol='triangle-down', color='red')\n",
    "    ))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title=\"Stock Price Paths with Trading Signals\",\n",
    "    xaxis_title=\"Days\",\n",
    "    yaxis_title=\"Price\",\n",
    "    hovermode=\"x unified\"\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Example dataframe\n",
    "dataframe = {\n",
    "    \"index\": list(range(10)),  # Replace with your real dataframe index\n",
    "    \"Delta_norm\": [100 + i * 2 for i in range(10)],  # Replace with your stock data\n",
    "}\n",
    "up_signals = [2, 6]  # Replace with your calculated up signals indices\n",
    "down_signals = [4, 8]  # Replace with your calculated down signals indices\n",
    "\n",
    "# Convert to a pandas-like structure if necessary\n",
    "import pandas as pd\n",
    "dataframe = pd.DataFrame(dataframe)\n",
    "\n",
    "# Adding the stock path\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=dataframe[\"index\"], \n",
    "    y=dataframe[\"Delta_norm\"], \n",
    "    mode='lines', \n",
    "    name='Stock Path'\n",
    "))\n",
    "\n",
    "# Adding up signals\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[dataframe[\"index\"][i] for i in up_signals],  # x-coordinates of up signals\n",
    "    y=[dataframe[\"Delta_norm\"][i] for i in up_signals],  # y-coordinates of up signals\n",
    "    mode='markers', \n",
    "    name='Up Signals', \n",
    "    marker=dict(size=10, symbol='triangle-up', color='green')\n",
    "))\n",
    "\n",
    "# Adding down signals\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[dataframe[\"index\"][i] for i in down_signals],  # x-coordinates of down signals\n",
    "    y=[dataframe[\"Delta_norm\"][i] for i in down_signals],  # y-coordinates of down signals\n",
    "    mode='markers', \n",
    "    name='Down Signals', \n",
    "    marker=dict(size=10, symbol='triangle-down', color='red')\n",
    "))\n",
    "\n",
    "# Show plot\n",
    "fig.update_layout(\n",
    "    title=\"Stock Path with Trading Signals\",\n",
    "    xaxis_title=\"Index\",\n",
    "    yaxis_title=\"Delta_norm\",\n",
    "    hovermode=\"x unified\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataframe\n",
    "pairs = [\"Pair 1\", \"Pair 2\", \"Pair 3\"]  # Replace with actual pair names\n",
    "dataframes = {\n",
    "    pair: pd.DataFrame({\n",
    "        \"index\": list(range(10)),\n",
    "        \"Delta_norm\": [100 + i * 2 + idx for i in range(10)]  # Example stock data\n",
    "    })\n",
    "    for idx, pair in enumerate(pairs)\n",
    "}\n",
    "\n",
    "signals = {\n",
    "    \"Pair 1\": {\"up\": [2, 6], \"down\": [4, 8]},\n",
    "    \"Pair 2\": {\"up\": [1, 5], \"down\": [3, 7]},\n",
    "    \"Pair 3\": {\"up\": [0, 9], \"down\": [2, 8]},\n",
    "}\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces for each pair\n",
    "buttons = []\n",
    "visibility = []\n",
    "\n",
    "for i, pair in enumerate(pairs):\n",
    "    df = dataframes[pair]\n",
    "    up_signals = signals[pair][\"up\"]\n",
    "    down_signals = signals[pair][\"down\"]\n",
    "\n",
    "    # Add stock path trace\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df[\"index\"],\n",
    "        y=df[\"Delta_norm\"],\n",
    "        mode='lines',\n",
    "        name=f'{pair} Path',\n",
    "        visible=False  # Initially hidden\n",
    "    ))\n",
    "    visibility.append(False)  # Track visibility state\n",
    "\n",
    "    # Add up signals trace\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[df[\"index\"][j] for j in up_signals],\n",
    "        y=[df[\"Delta_norm\"][j] for j in up_signals],\n",
    "        mode='markers',\n",
    "        name=f'{pair} Up Signals',\n",
    "        marker=dict(size=10, symbol='triangle-up', color='green'),\n",
    "        visible=False  # Initially hidden\n",
    "    ))\n",
    "    visibility.append(False)\n",
    "\n",
    "    # Add down signals trace\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[df[\"index\"][j] for j in down_signals],\n",
    "        y=[df[\"Delta_norm\"][j] for j in down_signals],\n",
    "        mode='markers',\n",
    "        name=f'{pair} Down Signals',\n",
    "        marker=dict(size=10, symbol='triangle-down', color='red'),\n",
    "        visible=False  # Initially hidden\n",
    "    ))\n",
    "    visibility.append(False)\n",
    "\n",
    "    # Add a button for this pair\n",
    "    button_visibility = [False] * len(visibility)\n",
    "    button_visibility[i * 3] = True  # Stock path\n",
    "    button_visibility[i * 3 + 1] = True  # Up signals\n",
    "    button_visibility[i * 3 + 2] = True  # Down signals\n",
    "\n",
    "    buttons.append({\n",
    "        \"label\": pair,\n",
    "        \"method\": \"update\",\n",
    "        \"args\": [{\"visible\": button_visibility}]\n",
    "    })\n",
    "\n",
    "# Add a \"Show All\" button\n",
    "buttons.append({\n",
    "    \"label\": \"Show All\",\n",
    "    \"method\": \"update\",\n",
    "    \"args\": [{\"visible\": [True] * len(visibility)}]\n",
    "})\n",
    "\n",
    "# Add a \"Hide All\" button\n",
    "buttons.append({\n",
    "    \"label\": \"Hide All\",\n",
    "    \"method\": \"update\",\n",
    "    \"args\": [{\"visible\": [False] * len(visibility)}]\n",
    "})\n",
    "\n",
    "# Add buttons to layout\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        {\n",
    "            \"buttons\": buttons,\n",
    "            \"direction\": \"down\",\n",
    "            \"showactive\": True,\n",
    "            \"x\": 0.1,\n",
    "            \"y\": 1.15,\n",
    "            \"xanchor\": \"left\",\n",
    "            \"yanchor\": \"top\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Add layout properties\n",
    "fig.update_layout(\n",
    "    title=\"Stock Path with Trading Signals\",\n",
    "    xaxis_title=\"Index\",\n",
    "    yaxis_title=\"Delta_norm\",\n",
    "    hovermode=\"x unified\"\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/Users/mcbookairdebat/Desktop/Projet/project/GitHub/Pair_trading_strategy/Pair_trading/data_import_enginnering.py:40: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[stock_name] = z[stock_name]\n",
      "/var/folders/lc/t3q2r39x05ndfqz7hm78wmkc0000gn/T/ipykernel_23276/2338739064.py:38: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  dataframe_normalized= dataframe_normalized.stack().stack().droplevel(level =2).unstack()\n",
      "/var/folders/lc/t3q2r39x05ndfqz7hm78wmkc0000gn/T/ipykernel_23276/2338739064.py:39: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  raw_dataframe= raw_dataframe.stack().stack().droplevel(level =2).unstack()\n"
     ]
    }
   ],
   "source": [
    "%run packages.py\n",
    "from data_import_enginnering import DataImportEnginnering\n",
    "from metric_selection import Pair_Selection\n",
    "from data_visualization import Data_Visualization\n",
    "import importlib\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "# 1. DATA\n",
    "## 1.1. Importation of data into a dictionary\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "tables = pd.read_html(url)\n",
    "Stock_list = pd.DataFrame(tables[0])\n",
    "Stock_list.drop(['Security','GICS Sub-Industry','Headquarters Location','CIK','Founded'],axis = 1, inplace=True)\n",
    "Stock_list['Date added'] = pd.to_datetime(Stock_list['Date added'])\n",
    "Stock_list = Stock_list[( Stock_list['Date added'] < '2023-12-31') & (Stock_list['Date added']>'2015-01-01')][['Symbol','GICS Sector']]\n",
    "stock_list = list(Stock_list['Symbol'].unique())\n",
    "Stock_list_sector = Stock_list.groupby('GICS Sector')['Symbol'].unique().to_dict()\n",
    "sector_list = list(Stock_list_sector.keys())\n",
    "pairs = {k:[tuple(sorted((i,j))) for i in Stock_list_sector[k] for j in Stock_list_sector[k] if j!=i] for k in sector_list}\n",
    "pairs = {k :sorted(list(set(pairs[k]))) for k in sector_list}\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2023-12-31'\n",
    "period = '1d'\n",
    "colone = ['Close']\n",
    "\n",
    "Enginner = DataImportEnginnering(stock_list,start_date=start_date,end_date=end_date,period=period,colone=colone)\n",
    "raw_data = Enginner.RawData()\n",
    "## 1.2. Normalisation of data\n",
    "raw_data_normalized = {}\n",
    "for key, value in raw_data.items():\n",
    "    raw_data_normalized[key] = Enginner.normalize(value)\n",
    "\n",
    "raw_data_normalized\n",
    "dataframe_normalized = Enginner.Dictionnary_to_Dataframe(raw_data_normalized)\n",
    "raw_dataframe = Enginner.Dictionnary_to_Dataframe(raw_data)\n",
    "dataframe_normalized= dataframe_normalized.stack().stack().droplevel(level =2).unstack()\n",
    "raw_dataframe= raw_dataframe.stack().stack().droplevel(level =2).unstack()\n",
    "#raw_data = first dictionnary with non normalised data for each ticker\n",
    "#raw_data_normalized = dictionnary with normalised data\n",
    "#raw_dataframe = raw_data into dataframe\n",
    "#dataframe_normalized = raw_data_normalized into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AOS</th>\n",
       "      <th>AMD</th>\n",
       "      <th>ABNB</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ARE</th>\n",
       "      <th>ALGN</th>\n",
       "      <th>LNT</th>\n",
       "      <th>AMCR</th>\n",
       "      <th>AWK</th>\n",
       "      <th>ANSS</th>\n",
       "      <th>...</th>\n",
       "      <th>UAL</th>\n",
       "      <th>VLTO</th>\n",
       "      <th>VRSK</th>\n",
       "      <th>VICI</th>\n",
       "      <th>WRB</th>\n",
       "      <th>WAB</th>\n",
       "      <th>WBD</th>\n",
       "      <th>WST</th>\n",
       "      <th>WTW</th>\n",
       "      <th>ZBRA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>23.956099</td>\n",
       "      <td>2.670000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.438381</td>\n",
       "      <td>65.044739</td>\n",
       "      <td>56.200001</td>\n",
       "      <td>24.159046</td>\n",
       "      <td>7.229086</td>\n",
       "      <td>44.470181</td>\n",
       "      <td>81.639999</td>\n",
       "      <td>...</td>\n",
       "      <td>66.339996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.555313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.155564</td>\n",
       "      <td>82.343567</td>\n",
       "      <td>34.480000</td>\n",
       "      <td>49.899395</td>\n",
       "      <td>100.853889</td>\n",
       "      <td>77.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>23.536947</td>\n",
       "      <td>2.660000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.699417</td>\n",
       "      <td>65.827110</td>\n",
       "      <td>56.990002</td>\n",
       "      <td>23.864769</td>\n",
       "      <td>7.229086</td>\n",
       "      <td>43.785900</td>\n",
       "      <td>80.860001</td>\n",
       "      <td>...</td>\n",
       "      <td>66.150002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.756638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.047566</td>\n",
       "      <td>80.481354</td>\n",
       "      <td>33.060001</td>\n",
       "      <td>49.210598</td>\n",
       "      <td>100.129456</td>\n",
       "      <td>76.339996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>23.344471</td>\n",
       "      <td>2.630000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.708199</td>\n",
       "      <td>66.160339</td>\n",
       "      <td>57.450001</td>\n",
       "      <td>23.788486</td>\n",
       "      <td>7.229086</td>\n",
       "      <td>43.901321</td>\n",
       "      <td>79.260002</td>\n",
       "      <td>...</td>\n",
       "      <td>64.580002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.544941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.016369</td>\n",
       "      <td>79.441505</td>\n",
       "      <td>31.980000</td>\n",
       "      <td>48.368736</td>\n",
       "      <td>99.631409</td>\n",
       "      <td>75.790001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>23.515564</td>\n",
       "      <td>2.580000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.508221</td>\n",
       "      <td>67.058601</td>\n",
       "      <td>59.570000</td>\n",
       "      <td>24.180840</td>\n",
       "      <td>6.919268</td>\n",
       "      <td>44.461937</td>\n",
       "      <td>79.709999</td>\n",
       "      <td>...</td>\n",
       "      <td>65.529999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.583416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.028372</td>\n",
       "      <td>80.216682</td>\n",
       "      <td>32.209999</td>\n",
       "      <td>49.153198</td>\n",
       "      <td>101.057617</td>\n",
       "      <td>77.720001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>24.127192</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.064579</td>\n",
       "      <td>67.826477</td>\n",
       "      <td>61.439999</td>\n",
       "      <td>24.562304</td>\n",
       "      <td>6.919268</td>\n",
       "      <td>44.635063</td>\n",
       "      <td>81.660004</td>\n",
       "      <td>...</td>\n",
       "      <td>66.639999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.189648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.285159</td>\n",
       "      <td>81.861473</td>\n",
       "      <td>32.470001</td>\n",
       "      <td>50.119423</td>\n",
       "      <td>102.212212</td>\n",
       "      <td>79.379997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22</th>\n",
       "      <td>80.431038</td>\n",
       "      <td>139.600006</td>\n",
       "      <td>140.800003</td>\n",
       "      <td>147.795898</td>\n",
       "      <td>120.820045</td>\n",
       "      <td>271.869995</td>\n",
       "      <td>49.126446</td>\n",
       "      <td>9.208629</td>\n",
       "      <td>128.629059</td>\n",
       "      <td>357.980011</td>\n",
       "      <td>...</td>\n",
       "      <td>42.549999</td>\n",
       "      <td>81.240837</td>\n",
       "      <td>234.797104</td>\n",
       "      <td>29.624878</td>\n",
       "      <td>45.678333</td>\n",
       "      <td>125.986504</td>\n",
       "      <td>11.270000</td>\n",
       "      <td>354.085541</td>\n",
       "      <td>236.304840</td>\n",
       "      <td>269.410004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-26</th>\n",
       "      <td>80.549126</td>\n",
       "      <td>143.410004</td>\n",
       "      <td>138.720001</td>\n",
       "      <td>150.060745</td>\n",
       "      <td>122.106262</td>\n",
       "      <td>274.190002</td>\n",
       "      <td>49.116798</td>\n",
       "      <td>9.208629</td>\n",
       "      <td>129.323242</td>\n",
       "      <td>360.880005</td>\n",
       "      <td>...</td>\n",
       "      <td>42.080002</td>\n",
       "      <td>81.728439</td>\n",
       "      <td>235.622162</td>\n",
       "      <td>29.927366</td>\n",
       "      <td>45.606766</td>\n",
       "      <td>126.275078</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>356.489807</td>\n",
       "      <td>235.320618</td>\n",
       "      <td>275.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>80.854210</td>\n",
       "      <td>146.070007</td>\n",
       "      <td>136.550003</td>\n",
       "      <td>147.037689</td>\n",
       "      <td>122.257591</td>\n",
       "      <td>275.279999</td>\n",
       "      <td>49.030003</td>\n",
       "      <td>9.246680</td>\n",
       "      <td>129.284134</td>\n",
       "      <td>358.899994</td>\n",
       "      <td>...</td>\n",
       "      <td>41.730000</td>\n",
       "      <td>82.813126</td>\n",
       "      <td>235.811035</td>\n",
       "      <td>30.078609</td>\n",
       "      <td>45.574242</td>\n",
       "      <td>126.513893</td>\n",
       "      <td>11.490000</td>\n",
       "      <td>355.033295</td>\n",
       "      <td>235.527298</td>\n",
       "      <td>275.790009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>80.932930</td>\n",
       "      <td>148.759995</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>147.145996</td>\n",
       "      <td>123.117210</td>\n",
       "      <td>276.670013</td>\n",
       "      <td>49.492920</td>\n",
       "      <td>9.237167</td>\n",
       "      <td>130.017426</td>\n",
       "      <td>361.859985</td>\n",
       "      <td>...</td>\n",
       "      <td>41.970001</td>\n",
       "      <td>82.723465</td>\n",
       "      <td>236.198715</td>\n",
       "      <td>30.418909</td>\n",
       "      <td>45.814960</td>\n",
       "      <td>126.334778</td>\n",
       "      <td>11.690000</td>\n",
       "      <td>354.085541</td>\n",
       "      <td>236.376724</td>\n",
       "      <td>275.350006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>81.129753</td>\n",
       "      <td>147.410004</td>\n",
       "      <td>136.139999</td>\n",
       "      <td>142.271667</td>\n",
       "      <td>121.082771</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>49.473629</td>\n",
       "      <td>9.170576</td>\n",
       "      <td>129.049469</td>\n",
       "      <td>362.880005</td>\n",
       "      <td>...</td>\n",
       "      <td>41.259998</td>\n",
       "      <td>81.946442</td>\n",
       "      <td>237.441299</td>\n",
       "      <td>30.135326</td>\n",
       "      <td>46.010139</td>\n",
       "      <td>126.275078</td>\n",
       "      <td>11.380000</td>\n",
       "      <td>351.282196</td>\n",
       "      <td>238.233597</td>\n",
       "      <td>273.329987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2264 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker            AOS         AMD        ABNB         ALB         ARE  \\\n",
       "Date                                                                    \n",
       "2015-01-02  23.956099    2.670000         NaN   52.438381   65.044739   \n",
       "2015-01-05  23.536947    2.660000         NaN   50.699417   65.827110   \n",
       "2015-01-06  23.344471    2.630000         NaN   49.708199   66.160339   \n",
       "2015-01-07  23.515564    2.580000         NaN   49.508221   67.058601   \n",
       "2015-01-08  24.127192    2.610000         NaN   51.064579   67.826477   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "2023-12-22  80.431038  139.600006  140.800003  147.795898  120.820045   \n",
       "2023-12-26  80.549126  143.410004  138.720001  150.060745  122.106262   \n",
       "2023-12-27  80.854210  146.070007  136.550003  147.037689  122.257591   \n",
       "2023-12-28  80.932930  148.759995  137.000000  147.145996  123.117210   \n",
       "2023-12-29  81.129753  147.410004  136.139999  142.271667  121.082771   \n",
       "\n",
       "Ticker            ALGN        LNT      AMCR         AWK        ANSS  ...  \\\n",
       "Date                                                                 ...   \n",
       "2015-01-02   56.200001  24.159046  7.229086   44.470181   81.639999  ...   \n",
       "2015-01-05   56.990002  23.864769  7.229086   43.785900   80.860001  ...   \n",
       "2015-01-06   57.450001  23.788486  7.229086   43.901321   79.260002  ...   \n",
       "2015-01-07   59.570000  24.180840  6.919268   44.461937   79.709999  ...   \n",
       "2015-01-08   61.439999  24.562304  6.919268   44.635063   81.660004  ...   \n",
       "...                ...        ...       ...         ...         ...  ...   \n",
       "2023-12-22  271.869995  49.126446  9.208629  128.629059  357.980011  ...   \n",
       "2023-12-26  274.190002  49.116798  9.208629  129.323242  360.880005  ...   \n",
       "2023-12-27  275.279999  49.030003  9.246680  129.284134  358.899994  ...   \n",
       "2023-12-28  276.670013  49.492920  9.237167  130.017426  361.859985  ...   \n",
       "2023-12-29  274.000000  49.473629  9.170576  129.049469  362.880005  ...   \n",
       "\n",
       "Ticker            UAL       VLTO        VRSK       VICI        WRB  \\\n",
       "Date                                                                 \n",
       "2015-01-02  66.339996        NaN   61.555313        NaN  12.155564   \n",
       "2015-01-05  66.150002        NaN   60.756638        NaN  12.047566   \n",
       "2015-01-06  64.580002        NaN   60.544941        NaN  12.016369   \n",
       "2015-01-07  65.529999        NaN   60.583416        NaN  12.028372   \n",
       "2015-01-08  66.639999        NaN   61.189648        NaN  12.285159   \n",
       "...               ...        ...         ...        ...        ...   \n",
       "2023-12-22  42.549999  81.240837  234.797104  29.624878  45.678333   \n",
       "2023-12-26  42.080002  81.728439  235.622162  29.927366  45.606766   \n",
       "2023-12-27  41.730000  82.813126  235.811035  30.078609  45.574242   \n",
       "2023-12-28  41.970001  82.723465  236.198715  30.418909  45.814960   \n",
       "2023-12-29  41.259998  81.946442  237.441299  30.135326  46.010139   \n",
       "\n",
       "Ticker             WAB        WBD         WST         WTW        ZBRA  \n",
       "Date                                                                   \n",
       "2015-01-02   82.343567  34.480000   49.899395  100.853889   77.430000  \n",
       "2015-01-05   80.481354  33.060001   49.210598  100.129456   76.339996  \n",
       "2015-01-06   79.441505  31.980000   48.368736   99.631409   75.790001  \n",
       "2015-01-07   80.216682  32.209999   49.153198  101.057617   77.720001  \n",
       "2015-01-08   81.861473  32.470001   50.119423  102.212212   79.379997  \n",
       "...                ...        ...         ...         ...         ...  \n",
       "2023-12-22  125.986504  11.270000  354.085541  236.304840  269.410004  \n",
       "2023-12-26  126.275078  11.500000  356.489807  235.320618  275.500000  \n",
       "2023-12-27  126.513893  11.490000  355.033295  235.527298  275.790009  \n",
       "2023-12-28  126.334778  11.690000  354.085541  236.376724  275.350006  \n",
       "2023-12-29  126.275078  11.380000  351.282196  238.233597  273.329987  \n",
       "\n",
       "[2264 rows x 156 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = raw_dataframe.shape[1]/raw_dataframe.shape[0]\n",
    "data = raw_dataframe.copy()\n",
    "data = np.log(data/data.shift(1))\n",
    "data = data.apply(lambda x: x-x.mean())\n",
    "data = data.iloc[1:,:]\n",
    "sigma = data.std().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AOS</th>\n",
       "      <th>AMD</th>\n",
       "      <th>ABNB</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ARE</th>\n",
       "      <th>ALGN</th>\n",
       "      <th>LNT</th>\n",
       "      <th>AMCR</th>\n",
       "      <th>AWK</th>\n",
       "      <th>ANSS</th>\n",
       "      <th>...</th>\n",
       "      <th>UAL</th>\n",
       "      <th>VLTO</th>\n",
       "      <th>VRSK</th>\n",
       "      <th>VICI</th>\n",
       "      <th>WRB</th>\n",
       "      <th>WAB</th>\n",
       "      <th>WBD</th>\n",
       "      <th>WST</th>\n",
       "      <th>WTW</th>\n",
       "      <th>ZBRA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AOS</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.308748</td>\n",
       "      <td>0.251244</td>\n",
       "      <td>0.426341</td>\n",
       "      <td>0.389819</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.269724</td>\n",
       "      <td>0.324171</td>\n",
       "      <td>0.290185</td>\n",
       "      <td>0.444652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354407</td>\n",
       "      <td>0.240933</td>\n",
       "      <td>0.404879</td>\n",
       "      <td>0.364455</td>\n",
       "      <td>0.411605</td>\n",
       "      <td>0.488058</td>\n",
       "      <td>0.310911</td>\n",
       "      <td>0.350117</td>\n",
       "      <td>0.399861</td>\n",
       "      <td>0.454786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMD</th>\n",
       "      <td>0.308748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.469071</td>\n",
       "      <td>0.334940</td>\n",
       "      <td>0.270459</td>\n",
       "      <td>0.362968</td>\n",
       "      <td>0.125116</td>\n",
       "      <td>0.183627</td>\n",
       "      <td>0.185099</td>\n",
       "      <td>0.465330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222773</td>\n",
       "      <td>0.115568</td>\n",
       "      <td>0.318088</td>\n",
       "      <td>0.287770</td>\n",
       "      <td>0.206694</td>\n",
       "      <td>0.261492</td>\n",
       "      <td>0.207752</td>\n",
       "      <td>0.344242</td>\n",
       "      <td>0.281367</td>\n",
       "      <td>0.376830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABNB</th>\n",
       "      <td>0.251244</td>\n",
       "      <td>0.469071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.453637</td>\n",
       "      <td>0.318239</td>\n",
       "      <td>0.413619</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.290734</td>\n",
       "      <td>0.152375</td>\n",
       "      <td>0.471075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486376</td>\n",
       "      <td>0.300481</td>\n",
       "      <td>0.242546</td>\n",
       "      <td>0.353143</td>\n",
       "      <td>0.142538</td>\n",
       "      <td>0.386082</td>\n",
       "      <td>0.356556</td>\n",
       "      <td>0.295133</td>\n",
       "      <td>0.241738</td>\n",
       "      <td>0.402930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>0.426341</td>\n",
       "      <td>0.334940</td>\n",
       "      <td>0.453637</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.358445</td>\n",
       "      <td>0.369607</td>\n",
       "      <td>0.239107</td>\n",
       "      <td>0.300952</td>\n",
       "      <td>0.260996</td>\n",
       "      <td>0.426606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345574</td>\n",
       "      <td>0.410889</td>\n",
       "      <td>0.313421</td>\n",
       "      <td>0.373707</td>\n",
       "      <td>0.361186</td>\n",
       "      <td>0.446773</td>\n",
       "      <td>0.314924</td>\n",
       "      <td>0.314693</td>\n",
       "      <td>0.331819</td>\n",
       "      <td>0.402798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARE</th>\n",
       "      <td>0.389819</td>\n",
       "      <td>0.270459</td>\n",
       "      <td>0.318239</td>\n",
       "      <td>0.358445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.383514</td>\n",
       "      <td>0.565065</td>\n",
       "      <td>0.382102</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.446575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324393</td>\n",
       "      <td>0.211563</td>\n",
       "      <td>0.494034</td>\n",
       "      <td>0.607094</td>\n",
       "      <td>0.470303</td>\n",
       "      <td>0.381622</td>\n",
       "      <td>0.295787</td>\n",
       "      <td>0.371187</td>\n",
       "      <td>0.428864</td>\n",
       "      <td>0.393103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAB</th>\n",
       "      <td>0.488058</td>\n",
       "      <td>0.261492</td>\n",
       "      <td>0.386082</td>\n",
       "      <td>0.446773</td>\n",
       "      <td>0.381622</td>\n",
       "      <td>0.377307</td>\n",
       "      <td>0.277151</td>\n",
       "      <td>0.358741</td>\n",
       "      <td>0.250538</td>\n",
       "      <td>0.375671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509206</td>\n",
       "      <td>0.446794</td>\n",
       "      <td>0.381929</td>\n",
       "      <td>0.473189</td>\n",
       "      <td>0.483015</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.359575</td>\n",
       "      <td>0.251090</td>\n",
       "      <td>0.399646</td>\n",
       "      <td>0.414570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBD</th>\n",
       "      <td>0.310911</td>\n",
       "      <td>0.207752</td>\n",
       "      <td>0.356556</td>\n",
       "      <td>0.314924</td>\n",
       "      <td>0.295787</td>\n",
       "      <td>0.269362</td>\n",
       "      <td>0.170523</td>\n",
       "      <td>0.247047</td>\n",
       "      <td>0.167588</td>\n",
       "      <td>0.247995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358691</td>\n",
       "      <td>0.276580</td>\n",
       "      <td>0.218448</td>\n",
       "      <td>0.309185</td>\n",
       "      <td>0.279422</td>\n",
       "      <td>0.359575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.190259</td>\n",
       "      <td>0.237521</td>\n",
       "      <td>0.302265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WST</th>\n",
       "      <td>0.350117</td>\n",
       "      <td>0.344242</td>\n",
       "      <td>0.295133</td>\n",
       "      <td>0.314693</td>\n",
       "      <td>0.371187</td>\n",
       "      <td>0.410712</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.235534</td>\n",
       "      <td>0.367771</td>\n",
       "      <td>0.511565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138025</td>\n",
       "      <td>0.293315</td>\n",
       "      <td>0.463811</td>\n",
       "      <td>0.266344</td>\n",
       "      <td>0.270051</td>\n",
       "      <td>0.251090</td>\n",
       "      <td>0.190259</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.332527</td>\n",
       "      <td>0.371809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTW</th>\n",
       "      <td>0.399861</td>\n",
       "      <td>0.281367</td>\n",
       "      <td>0.241738</td>\n",
       "      <td>0.331819</td>\n",
       "      <td>0.428864</td>\n",
       "      <td>0.311308</td>\n",
       "      <td>0.386083</td>\n",
       "      <td>0.311290</td>\n",
       "      <td>0.368583</td>\n",
       "      <td>0.457402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343754</td>\n",
       "      <td>0.065016</td>\n",
       "      <td>0.496357</td>\n",
       "      <td>0.431153</td>\n",
       "      <td>0.512897</td>\n",
       "      <td>0.399646</td>\n",
       "      <td>0.237521</td>\n",
       "      <td>0.332527</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>0.454786</td>\n",
       "      <td>0.376830</td>\n",
       "      <td>0.402930</td>\n",
       "      <td>0.402798</td>\n",
       "      <td>0.393103</td>\n",
       "      <td>0.424024</td>\n",
       "      <td>0.186673</td>\n",
       "      <td>0.287292</td>\n",
       "      <td>0.249405</td>\n",
       "      <td>0.515702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329458</td>\n",
       "      <td>0.492977</td>\n",
       "      <td>0.386241</td>\n",
       "      <td>0.408599</td>\n",
       "      <td>0.340984</td>\n",
       "      <td>0.414570</td>\n",
       "      <td>0.302265</td>\n",
       "      <td>0.371809</td>\n",
       "      <td>0.350426</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker       AOS       AMD      ABNB       ALB       ARE      ALGN       LNT  \\\n",
       "Ticker                                                                         \n",
       "AOS     1.000000  0.308748  0.251244  0.426341  0.389819  0.366369  0.269724   \n",
       "AMD     0.308748  1.000000  0.469071  0.334940  0.270459  0.362968  0.125116   \n",
       "ABNB    0.251244  0.469071  1.000000  0.453637  0.318239  0.413619  0.005245   \n",
       "ALB     0.426341  0.334940  0.453637  1.000000  0.358445  0.369607  0.239107   \n",
       "ARE     0.389819  0.270459  0.318239  0.358445  1.000000  0.383514  0.565065   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "WAB     0.488058  0.261492  0.386082  0.446773  0.381622  0.377307  0.277151   \n",
       "WBD     0.310911  0.207752  0.356556  0.314924  0.295787  0.269362  0.170523   \n",
       "WST     0.350117  0.344242  0.295133  0.314693  0.371187  0.410712  0.295455   \n",
       "WTW     0.399861  0.281367  0.241738  0.331819  0.428864  0.311308  0.386083   \n",
       "ZBRA    0.454786  0.376830  0.402930  0.402798  0.393103  0.424024  0.186673   \n",
       "\n",
       "Ticker      AMCR       AWK      ANSS  ...       UAL      VLTO      VRSK  \\\n",
       "Ticker                                ...                                 \n",
       "AOS     0.324171  0.290185  0.444652  ...  0.354407  0.240933  0.404879   \n",
       "AMD     0.183627  0.185099  0.465330  ...  0.222773  0.115568  0.318088   \n",
       "ABNB    0.290734  0.152375  0.471075  ...  0.486376  0.300481  0.242546   \n",
       "ALB     0.300952  0.260996  0.426606  ...  0.345574  0.410889  0.313421   \n",
       "ARE     0.382102  0.578947  0.446575  ...  0.324393  0.211563  0.494034   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "WAB     0.358741  0.250538  0.375671  ...  0.509206  0.446794  0.381929   \n",
       "WBD     0.247047  0.167588  0.247995  ...  0.358691  0.276580  0.218448   \n",
       "WST     0.235534  0.367771  0.511565  ...  0.138025  0.293315  0.463811   \n",
       "WTW     0.311290  0.368583  0.457402  ...  0.343754  0.065016  0.496357   \n",
       "ZBRA    0.287292  0.249405  0.515702  ...  0.329458  0.492977  0.386241   \n",
       "\n",
       "Ticker      VICI       WRB       WAB       WBD       WST       WTW      ZBRA  \n",
       "Ticker                                                                        \n",
       "AOS     0.364455  0.411605  0.488058  0.310911  0.350117  0.399861  0.454786  \n",
       "AMD     0.287770  0.206694  0.261492  0.207752  0.344242  0.281367  0.376830  \n",
       "ABNB    0.353143  0.142538  0.386082  0.356556  0.295133  0.241738  0.402930  \n",
       "ALB     0.373707  0.361186  0.446773  0.314924  0.314693  0.331819  0.402798  \n",
       "ARE     0.607094  0.470303  0.381622  0.295787  0.371187  0.428864  0.393103  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "WAB     0.473189  0.483015  1.000000  0.359575  0.251090  0.399646  0.414570  \n",
       "WBD     0.309185  0.279422  0.359575  1.000000  0.190259  0.237521  0.302265  \n",
       "WST     0.266344  0.270051  0.251090  0.190259  1.000000  0.332527  0.371809  \n",
       "WTW     0.431153  0.512897  0.399646  0.237521  0.332527  1.000000  0.350426  \n",
       "ZBRA    0.408599  0.340984  0.414570  0.302265  0.371809  0.350426  1.000000  \n",
       "\n",
       "[156 rows x 156 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = data.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>PCA()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Marchenko pastur needs \n",
    "pts =156\n",
    "q = raw_dataframe.shape[1]/raw_dataframe.shape[0]\n",
    "sigma = data.std().mean()\n",
    "l_plus = sigma*(1+ 1/np.sqrt(q))**2\n",
    "l_moins = sigma*(1 - 1/np.sqrt(q))**2\n",
    "eVal = np.linspace(l_moins, l_plus, pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "values= q / (2 * np.pi * sigma * eVal) * ((l_plus - eVal) * (eVal - l_moins)) ** .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Line2D.set() got an unexpected keyword argument 'bins'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplained_variance_ratio_\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m156\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.9/site-packages/matplotlib/pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3798\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.9/site-packages/matplotlib/axes/_axes.py:1779\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1778\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py:296\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    295\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py:534\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(result)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [l[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py:534\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(result)\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [l[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[0;32m~/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py:527\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel must be scalar or have the same length as the input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(label)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_datasets\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m datasets.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 527\u001b[0m result \u001b[38;5;241m=\u001b[39m (\u001b[43mmake_artist\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mncx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mncy\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    529\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m j, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(labels))\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_kwargs:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(result)\n",
      "File \u001b[0;32m~/.venv/lib/python3.9/site-packages/matplotlib/axes/_base.py:335\u001b[0m, in \u001b[0;36m_process_plot_var_args._makeline\u001b[0;34m(self, axes, x, y, kw, kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m kw \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}  \u001b[38;5;66;03m# Don't modify the original kw.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setdefaults(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getdefaults(kw), kw)\n\u001b[0;32m--> 335\u001b[0m seg \u001b[38;5;241m=\u001b[39m \u001b[43mmlines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLine2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seg, kw\n",
      "File \u001b[0;32m~/.venv/lib/python3.9/site-packages/matplotlib/lines.py:407\u001b[0m, in \u001b[0;36mLine2D.__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, gapcolor, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_markeredgewidth(markeredgewidth)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# update kwargs before updating data to give the caller a\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# chance to init axes (and hence unit support)\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpickradius \u001b[38;5;241m=\u001b[39m pickradius\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mind_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.venv/lib/python3.9/site-packages/matplotlib/artist.py:1216\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;124;03m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;124;03m    errors as if calling `set`.\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_props\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{cls.__name__}\u001b[39;49;00m\u001b[38;5;124;43m.set() got an unexpected keyword argument \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{prop_name!r}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.9/site-packages/matplotlib/artist.py:1190\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1188\u001b[0m             func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1189\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[0;32m-> 1190\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1191\u001b[0m                     errfmt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), prop_name\u001b[38;5;241m=\u001b[39mk))\n\u001b[1;32m   1192\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(func(v))\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n",
      "\u001b[0;31mAttributeError\u001b[0m: Line2D.set() got an unexpected keyword argument 'bins'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pca.explained_variance_ratio_,bins=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
